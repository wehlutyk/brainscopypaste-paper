\documentclass[a4paper,10pt]{article}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{utopia}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[authoryear,round,compress]{natbib}
\usepackage{multicol}
\usepackage[usenames,dvipsnames]{color}
\usepackage{url}
\usepackage{eurosym}
\usepackage{array}
\usepackage{tabularx}
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{wrapfig}

\usepackage{float}
\usepackage{enumerate}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[frenchb]{babel}
\usepackage{setspace}
\setstretch{1.05}

\newcommand{\itx}[1]{\begin{itemize}#1\end{itemize}}
\newcommand{\enx}[1]{\begin{enumerate}#1\end{enumerate}}
\newcommand{\x}{\item}


\usepackage[bookmarks, colorlinks, breaklinks, pdftitle={Research project},pdfauthor={Camille Roth}]{hyperref}  
\hypersetup{linkcolor= MidnightBlue,citecolor= MidnightBlue,filecolor=black,urlcolor= MidnightBlue} 

\title{Manuscript CS15-80\medskip\\
{\Large\em``The semantic drift of quotations in blogspace: a case study in short-term cultural evolution''}
\bigskip\\Response to Reviewers
}
\author{Sébastien Lerique and Camille Roth}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
%\section{}
%\subsection{}

\makeatletter
\renewcommand{\subsection}{\clearpage\@startsection{section}{1}{0mm}
{\baselineskip}{\baselineskip\medskip\hrule\medskip}{\raggedright\Large\bf~\textcolor{MidnightBlue}}}
\makeatother


\newcommand{\critique}[1]{\begin{quote}#1\end{quote}}
\newcommand{\answer}[1]{{\setlength{\parindent}{0pt}\par\color{blue} #1}}
\newcommand{\answerok}[1]{{\setlength{\parindent}{0pt}\par\color{MidnightBlue} #1}}
\newcommand{\unclear}[1]{\textcolor{red}{\sf [C: #1]}}

\vspace{3cm}
Dear Todd Gureckis,

\medskip
We enclose an extensively revised version of the manuscript CS15-80 (initially titled ``How do we copy and paste? The semantic drift of quotations in blogspace'') based on the report you sent us on Jul 18, 2015.

\medskip
We hope that we have appropriately addressed the detailed remarks and very constructive questions made by you and the referees: to this effect, we also provide below a detailed response to each of these comments.  We additionally used a different color to emphasize the portions which were thoroughly rewritten.

\medskip
This comprehensive revision work led to a significantly longer manuscript than was originally submitted --- from around 6,300 words to about 9,000 words now, making it closer to a ``regular article'' than a ``brief report'': we hope that this will not be problematic at this stage.

\medskip
We look forward to reading your feedback on this new manuscript and apologize in advance for this long revision round.

\medskip
Best wishes,

\medskip
Sébastien Lerique and Camille Roth

\subsection*{Editor}
\critique{
1. The main results of the paper are based on a lot of arbitrary decisions about how various quantities are defined.  I am interested if small differences in these choices radically changes the conclusions you would draw, and how many other approaches you tried before you arrived at the data patterns you present.  All the reviewers agreed on this point (asking for more clarification about feature selection, why certain choices were made in the analysis, etc…).  This ranges from what types of quotes were included, to the rules to detecting substitution errors, to the inclusion of certain features in your analyses.  The reader needs to be convinced that the few “strong” looking patterns you do find are not too dependent on these arbitrary choices.  I actually question if this is the best way to address this question (effect of memory and linguistic variables on copy errors) given the noisiness of the data and the difficult in attributing copying errors to any particular parent
source.

}

\answer{
Point to:
- work on the substitution models showing that the results are robust
- the rationalization of feature selection
- clarifications of choices, such a single-substitution restriction
- precision/recall analyses for all filters
}

\critique{
2. The conclusions about “contractile” processes seem pretty speculative (as almost all reviewers agreed).   Sure, this might be the theoretical implication of iterating this substitution process, but you do not present any further evidence of this type of contraction towards a fixed point.  I think if you want to make this a major conclusion of the paper there is more work to be done.  Also this idea has been explored, in my view, in a much more sophisticated way in the iterated learning literature (e.g., Kalish, Lewandowsky, Griffiths, Kirby… see my PDF comments for specific references).  You should really check these arguments and papers out because you really have an iterated learning task.
} 

\answer{We agree the presentation was too much. Point to:
- the integration of the iterated learning literature in review and general discussion
- the fact that the constraints of the data don't let us explore chains, so we explained our claims more appropriately
}

\critique{3. The writing of this paper is of very low quality compared to what is expected at the journal.  I will email separately a very detailed editing of the paper via Adobe Acrobat where I tried to point these problems out.  However, it simply couldn’t be published without a nearly complete re-write or very heavy editing.
}

\answer{Thank you. We paid a lot of attention to the writing style in this new version, as can be seen in the large rewrites of many paragraphs.}

%\critique{
%The bottom line is that while I think this is a really interesting idea/question, this is not the best execution of this idea that I could imagine being published in the journal.  My gut reaction is that this paper needs a lot of work, additional analysis, and rewriting before it could be published and therefore should be rejected.  However, because the reviewers are unanimously more positive in their evaluation I will invited a revision for this in the hope that you can make it a pretty significant change and can benefit from the excellent and detailed reviewer comments.
%
%So you understand what is requested:  typically papers which are revised at Cognitive Science are returned with a detailed cover letter responding to each of the reviewer comments in detail, along with pointers to what has changed in the paper.  I would appreciate this type of cover letter if you choose to resubmit because it can help me and the reviewers process what changes you made.
%
%Sincerely,
%Todd Gureckis
%Associate editor
%}
%
%\answer{
%}

\subsection*{Reviewer \#1}

\critique{I think this is an interesting approach and dataset for better understanding how sentences are recalled and how paraphrases are constructed.  However, I think that the experiment design needs to be refined, and the project as a whole needs to be better connected to larger theoretical problems and better grounded within cognitive science.
} 

\answer{Point to:
- the revamped introduction, review of related work, and discussion of results which connects our approach to the literature
}

\critique{
Starting with the grounding, the Introduction talks about theories of "knowledge transmission mechanisms" but doesn't provide examples aside from the quote-copying problem. The theories also don't re-appear in the results discussion, leaving the experimental results stranded and unconnected to any larger domain.  No discussion of sentence recall tasks within psycholinguistics is given - there isn't a huge literature on this, but there are at least a few papers that should inform this work, such as Potter \& Lombardi 1990 "Regeneration in the short-term recall of sentences". No discussion is made about whether and how much the substitutions change the quotes (e.g., is the substituted word a synonym, phonological-neighbor, or something else? - cf. Lauf et al 2013 "Analyzing Variation Patterns in Quotes Over Time"). Lastly, the meaning of the analysis (pg. 17-19) of this process as a dynamical system with "cultural attractors" is not fleshed out - why doesn't this predict that all quotes will eventually, through substitution, converge to the same string? (Does it?) As a result, the conclusion that psycholinguistic factors don't have a big impact on substitution likelihood is interesting but doesn't have clear theoretical repercussions, or any clear meaning outside the very specific problem of quote replication.  This needs to be substantially revised and expanded to make this work useful to the audience at large.
} 

\answer{Point to:
- the new discussion of results
- the improved review of literature
- the use of H00 to compare to synonyms, and the small exploration of distances travelled by substitutions on the FA and synonym networks
}

\critique{ The experiment design also has some substantial flaws. First, some crucial factors were not considered - most notably, part of speech. I suspect, for instance, that pronouns and other closed-class words less often substituted than open-class words.  Phonological neighborhood density could also be important, though probably less so.  Second, no analysis was done that included all of the factors in, e.g., a multi-feature regression model.  While the features being considered are not strongly correlated, they are still likely to interact - especially if part-of-speech is added.  Third, the restriction to single-word substitutions introduces some significant confounds.  I'm not convinced that correctly and incorrectly copying a quote should be viewed as separate behaviors.  But more importantly, the $\sigma_\phi(f)$ calculation can be misleading under the single-substitution restriction:
}

\answer{
Point to:
- susceptibility of POS, showing that the effect (closed/open class words being different) expected is very small at best (closed class words would be stopword-likes in our graph)
- added phonological neighbourhood density as a feature
- the multi-feature regression of variation upon substitution, showing that variation of a feature is predicted mainly by the same source feature
- the expansion of substitution models to two-substitutions, giving the same results as single-substitutions. Notebooks for all models can be found at https://github.com/wehlutyk/brainscopypaste/tree/master/data/notebooks , and the graphs produced by those notebooks can be found at https://github.com/wehlutyk/brainscopypaste/tree/master/data/figures/susceptibility.ipynb .
}

\critique{Consider a toy case where all quotes are two words, and there is a single binary feature $F$. $p(F=1) = 3/4$, and the true substitution probabilities, given the value of F, are $p(S|F=1)=1$, $p(S|F=0)=1/2$.  All the quotes where both words have feature $F=1$ will have two substitutions and be omitted from the dataset, as will half of the quotes with one $F=1$ \& one $F=0$ word.  Half of the quotes with two $F=0$ words will also be omitted for having no substitutions.  Due to these omissions, if you actually generate some test data and calculate the $\sigma_F$ values, the $\sigma_F(1)$ value is correctly estimated as 1, but the $\sigma_F(0)$ value is erroneously estimated as 1/8 (not 1/2), because the $F=0$ words are never substituted in the $F=1/F=0$ pairs, and these are three times more common than the $F=0/F=0$ pairs.  I haven't run more complicated cases, such where the length of the quotes vary, but this leads me to have limited confidence that the estimates in the Figure 4 are appropriate to draw conclusions from. I would want to see either a mathematical analysis with realistic values showing that the error is expected to be small in this data or an expansion to include multiple-substitution examples to avoid this problem.
}

\answer{This case is indeed valid, if there is such a feature (F=1 here) that:
(a) is extremly frequent,
(b) is extremely substituted,
(c) interacts strongly with another feature so that both are often substituted together.

The combination of (a) and (b) is an anti-pattern in our results (more frequent =less substituted), so we could in theory give a bound to the worst error that could have been committed.
However we extend our substitution models to two-substitutions, and observe that the results do not change.
}

\critique{ Some high-level suggestions:
\itx{
\x more discussion of what dynamical systems are and especially their interpretation in this task before their appearance in the results
\x needs a substantive discussion of the results}
}

\answer{Point to rewrite of introduction and the added discussion of results.}

\critique{\itx{
\x show that the phi value is capturing what it purports to capture
\x and that the factors aren't conflated with length
\x is the single-substitution biasing the data?
\x make sure that the reported measures are interpretable
\x if low-frequency words have 1/3 chance of being chosen as substitution (Fig. 4), what if there are four low-frequency words in a quote?
}
}

\answer{
Point to:
- our control of single-substitution bias
- the change in definition of phi. Indeed it was confusing to present it (and measure it) as a probability (which it was, but an aggregated global one, not an in-sentence one), we now measure it as the strength of a bias.
}

\critique{\itx{
\x improving statements of motivation and grounding within cognitive science
\x what are representation transformation processes?
\x give examples in the introduction
\x show how the quotation test case connects to more general representation transformation?}
}

\answer{
Point to improved introduction and added discussion. Especially the connection with iterated learning literature.
}

\critique{\itx{
\x what about the semantics of quote replication?
\x does part of speech influence substitution rate?
\x can you quantify the semantic distance between the original and substituted quote (e.g., get Mechanical Turkers to rate the semantic distance?)}
}

\answerok{We added a discussion on the semantics of substituted quotes. We first aimed at quantifying the semantic distance by estimating the distance ``traveled'' by the substituted word in the WordNet hyperonym-hyperonym network as well as the FA network.  Substituted and substituting words are rarely synonyms, yet substitutions usually replace a word with a semantically-related word which achieves a similar meaning in the given context \unclear{voir ma question sur le manuscrit principal, ceci dit / d'ailleurs il faut faire gaffe car H00 concerne les synonymes, qui finalement ne sont pas si efficaces}. 

We also examined the effect of part-of-speech (POS): Figure 5 details the results on five POS categories. A Goodman-based multinomial goodness-of-fit shows that POS categories do not capture any significant bias in the selection of substitution targets, which is why we largely keep them outside of our analysis.
}
%\answer{ Point to: - the added POS analysis - the short discussion of distances travelled upon substitution }

\critique{\itx{
\x what happens when you run a multi-factor regression model? Do the features interact?
}}

\answerok{Thank you for this question, we decided to introduce a simple regression model to check feature interaction, see the discussion related to Fig. 8 (in a nutshell: we show that features generally do not interact).}

\critique{\itx{
\x clarify from the beginning the predictions you are making so that the results will be interpretable 
}}

\unclear{Voir le point {\bf (7)} de mon email}

\critique{Some low-level points:\itx{
\x the in vitro/in vivo distinction is unfamiliar and ought to be defined in the text
}
}

\answerok{In light of this potential unfamiliarity, we preferred to entirely avoid referring explicitly to this dichotomy (for instance, we now speak of ``corpus-based utterances'' instead of ``in vivo'').}

\critique{\itx{
\x introducing eight measures and then removing three of them due to collinearity is presentationally confusing}}

\unclear{ah oui que répond-on là? qqch comme ça?:}
\answer{We agree that introducing (now) twelve measures before eventually keeping six of them could complicate the flow of the section on word-level measures. However, we found it more natural to first propose a comprehensive, literature-based list of candidate features before addressing the quantitative analysis with a reduced yet sufficient set of metrics --- especially now that this section has been significantly expanded. We initially favored this solution over first presenting the final list of candidate features and justifying afterwards that they are anyway correlated with a broader list of traditional variables. (NB: An alternative option could consist in presenting the contents of Figs. 1 and 2 in the same figure, if this could be less confusing.)}

\critique{
\itx
{
\x was there a reason to expect that \# of synonyms and \# of phonemes would interact (Fig. 4)?]
}
}

\answer{
Yes, because of the similar curve shapes they had.
We removed number of phonemes now (in favor of number of letters), and number of synonyms doesn't show any effect of susceptibility on the new, improved measure.
}
\unclear{ne serait-ce pas plutôt la raison suivante?\\Except for word frequency, we observed that synonyms and phonems were the only two word features to exhibit an effect on susceptibility (and q quite similar effect for that matter). We thus reasoned that they were good candidates to look for and illustrate potential joint effects.\\However, the revised version now features a much braoder framework to statistically assess joint effects (see Fig. 8), we think it favorably replaces the previous variable-to-variable correlation check (NB: we also replaced the number of phonemes with the number of letters, which makes more sense in our context; letters and synonyms do not seem to interact).}

\critique{\itx{
\x how are you binning the continuous-valued features into categorical features for Fig 4 \& 5?
\x are there multiple y=x crossovers in Fig 5 if more bins are used?}
}

\answer{\unclear{comment était fait le binning avant, d'ailleurs? j'aurais eu envie de dire "integer-based" mais à la vue de l'ancien PDF ça ne colle pas avec les graphiques, et j'ai l'impression qu'on n'en parlait pas non plus -- auquel cas la réponse devrait aussi faire mention de l'avant, qui était probablement l'objectif de la question du reviewer} 
Binning is now by quantiles (makes more sense for the confidence intervals), but the extended notebooks (https://github.com/wehlutyk/brainscopypaste/tree/master/data/notebooks and https://github.com/wehlutyk/brainscopypaste/tree/master/data/figures/susceptibility.ipynb) also include graphs with the fixed-width bins we presented in the first version.
No multiple crossovers were ever observed.
}

\subsection*{Reviewer \#2}
\critique{This is a review of "How do we copy and paste? The semantic drift of quotations in blogspace." This paper attempts to discover the underlying psycholinguistic variables that is involved in blog authors making mistakes in the copying of quotations across time. Although I think the motivations and goals of this article are interesting and noteworthy, I think the actual analysis needs improvement in a number of areas.

Although I appreciate the brief writeup on intrusions in recall, the article fails to capture the amount of research done on this topic. Going back to Deese (1959; the precursor to modern experimental studies on false memory) and the subjective organization results of Tulving (1962) it has been well known that extra-list intrusions in free recall are often semantic in nature, with the intruding word being very similar in meaning to a studied item. A recent study that reinforces this is one by Zaromb, et al. (2006; JEP:LMC).
}

\answer{Thank you for these very useful and, indeed, relevant pointers.  We accordingly devoted a significant portion of the literature review to the issue of recall (see the ``Related work'' section).}

\critique{ This leads into a larger issue: there is no direct word-word semantic similarity score included in the psycholinguistic variables in the analysis. Global measures such as clustering coefficients based on free association norms are included, but this isn't as appropriate, since as the authors find, the vast majority of words that are being substituted are low frequency words. Low frequency words are not as well represented in the Nelson norms, given that they are less likely to be produced, and are thus less likely to have an appropriate clustering coefficient from this dataset. Variables based on corpus analyses need to be included to provide an appropriate overview of the impacts of semantics on this task. Even so, I would suspect that global semantic network measures are not nearly as important as word-word metrics.
}

\answer{Point to:
- discussion of why we use word features (intro + related work), 
- why we don't do exact word prediction (related work showing the question is not even mastered for random word lists in the laboratory, so forget about sentences in out-of-laboratory data), 
- clustering coefficient is not so central to our results now
- the addition of H00 gives insight into what the new words are w.r.t. to synonyms of the disappearing word
}

\critique{I would guess that the substitutions that are made in quotations are overwhelmingly higher frequency, highly semantically similar words. As the example on pg. 19 states, the substitution was "world" for "globe," where a higher frequency word replaced a lower frequency, semantically related word. There are a number of different models that can be used to assess this type of similarity, with the classic model being latent semantic analysis (Landauer \& Dumais, 1997). There are a number of additional models that have been proposed, such as Topics (Griffiths, Steyvers, \& Tenenbaum, 2007, Psyc Review) or Beagle (Jones \& Mewhort, 2007, Psyc Review). These models differ in their implementational complexity, but there are tools available that allow for useful statistics to be acquired easily. A tool by Recchia \& Jones (2010, BRM) allows for pointwise mutual information (PMI) of different words to be retrieved from a given corpus very simply. A tool such as this would allow for word-word similarity to be included in the analysis.

I understand that word-word metrics are not easily introduced in the type of analysis that the authors are attempting to do, where the analysis of the contributions of different global psycholinguistic variables are being weighed against each other. I just think that type of analysis is inappropriate here. Since the quotations were selected on the basis of single substitutions, it seems to me that the appropriate level of analysis is what properties of the word that is being substituted is the most predictive of the substitution. I suspect that the combination of frequency and semantic similarity will be by far the most predictive variables, consistent with past results on recall.
}

\answer{
Point to:
- discussion of distance travelled by substitution on FA and synonyms networks
- our data is ill-shaped for the kind of topic modelling suggested (aside from the earlier point that even with experiments in the laboratory, such tools don't predict so well)
}

\critique{Beyond this, I think the authors are missing out on the most interesting aspect of the data that they have collected: how the surrounding context of the quotation used is changing across time. That is, the quote is being propagated, and the prior usage of that quote is likely predictive of how that information is spread. This is likely a dynamical process where multiple news sources are used to construct a new blog post, and being able to analyze this type of information propagation would be a very interesting study. I point to the semantic space models cited (and the work derived from them) as being very useful tools to analyze this type of question.
}

\answer{That would indeed be interesting, but not our goal in the paper.}

\subsection*{Reviewer \#3}
\critique{In this paper, the authors analyze a large data set of quotations taken from a variety of news sources to study the form of substitutions in quotes, to determine if the transformations follow expected patterns given psycholinguistic theory.  Specifically, the words that are likely to be substituted are found to be less frequent words, and the pattern of substitution is such that the substituting word is more frequent, acquired earlier, and has lower clustering in the free-association word network.  These patterns are consistent with expected cognitive biases.

There are a few issues I would want to see addressed.
\bigskip

Foremost is the method of detecting substitution.  I understand that, given the data set, there is no perfect way to identify what quote is a transformation of what quote, and that it is not feasible to test all possible methods AND that it is simpler to focus on one method for the purposes of the paper.  However, given that this decision of which method to use can directly influence the main conclusions, it behooves the authors to do some sort of robustness check around this method.  For example, one could imagine two distinct groups that only exactly copy from themselves and never copy from each other, where one always publishes earlier than the other.  If the earlier-publishing group tended to select variations of quotes that used lower-frequency words, and the later-publishing group tended to select variations of quotes that used higher-frequency words, this method would infer many more low-frequency to high-frequency substitutions than actually existed.  This may not be a likely scenario, but it demonstrates the benefit of a robustness check. Trying the same analysis with one or two different substitution models would strengthen the authors' claims.
}

\answer{Point to:
- the several substitution models implemented, tested, and checked}

\critique{ A second issue is the time spent on feature selection.  It is unclear why the authors do feature selection at all, as "the analysis is done on a per-feature basis."  It would again add to the robustness of their claims if they showed that all of the correlated features show the same pattern of susceptibility and bias in substitution.  In the same vein, it is not clear why the authors claim that age of acquisition, frequency, and number of synonyms have low levels of correlation "excluding the network properties".  Why would one ignore the correlations with the network features?
}

\answer{Point to:
- the improved substitution selection section
- the graphics for the other features, available in the notebooks (https://github.com/wehlutyk/brainscopypaste/tree/master/data/notebooks) and figures (https://github.com/wehlutyk/brainscopypaste/tree/master/data/figures/susceptibility.ipynb), which we can put in a Supplementary Information if needed
}

\critique{
One smaller issue has to do with the filtering of the quotations.  The authors manually inspected the filtered quotes to see how many real event-related utterances are incorrectly filtered, but I would argue the precision of the filter is more important than the recall; how many of the kept quotes are not real event-related utterances?  Why not do manual coding of those and report that accuracy?
} 

\answer{Yes thank you, this is done now.}

\critique{ Finally, while I understand the appeal of doing a dynamic systems analysis to find the convergence points of the substitutions, but it is not really valid here.  The analysis in this paper does not provide information on what happens with multiple substitutions, so the authors cannot really make claims about the convergence points given this methodology.
}

\answer{We better explained our claims without overstating our findings.}

\critique{Overall, the analysis of the patterns of substitution in a series of quotations to validate psycholinguistic theory is novel and advances the current science.  The results would be more solid with some additional robustness checks, but in general they are quite intuitive.  I hope in the future the authors find a dataset that provides certain information about the transmission of language from one person to another, as this would allow for stronger claims about causality and greater confidence in the pattern of substitutions, as well as a finer-grained analysis of repeated substitutions.
}

\answer{On a side note, we entirely agree with the relevance of pursuing this research program in these directions, as the \emph{in vitro} observation of information transmission and its evolution is part of an ongoing project (which nonetheless remains beyond the scope of the current paper).}

{\small
\bibliographystyle{../../authordate1}
\bibliography{../../mainbiblio-u8}
}
 
 \end{document}