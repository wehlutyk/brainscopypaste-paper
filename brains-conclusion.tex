% !TEX root = brainscopycut.tex
\section{Discussion}

\todo{Discuss related to introduction. Attractors, lineage with specification, what we couldn't observe, how it fits into Kirby.
}



\todo{\#15: relate to missed literature}

\begin{new}

ADDTHIS:
We also chose exploratory vs. predictive to give a detailed view of what happens and because there's too many possible things to predict.

ADDTHIS:
By characterizing substitutions with 6 features on the disappearing and appearing words, we identify what makes a substitution more likely, and how a word changes when it is substituted.
Consistent with known effects in linguistics, we observe that low-frequency words and words learned later in development are more susceptible to substitution than other words.
Looking at the context those words appear in, we observe a marked effect for substitution of extreme words in a sentence (either very high-valued or very low-valued features compared to sentence average, except for word frequency).
Focusing on how words are transformed, we see that the appearing words have significantly higher frequency and lower age-of-acquisition than synonyms of the disappearing word.
Finally, the patterns we observe are also consistent with an attraction of each of the features towards a (feature-specific) asymptotic value.

ADDTHIS:
It is possible however, that these attractors appear due to an interaction between biases and sentence context, making it a contingency rather than a rule. This is not really dealt with (context, aside from relevance) by Sperber.

Attraction can also be defined on any number of dimensions. It can be on the structure, on anything, so saying there could be an attraction while not specifying the dimension is really meaningless. What's more important is to look at a specific dimension, and see if there's attraction on that one, as we did here for features.

We could've done also on semantic grouping, predicting the new word based on semantic similarity (or on frequent dyads, i.e. collocation with previous word the same way Zaromb et al. 2006 explain PLIs), and predicting the disappearing word based on the cost of doing such a substitution (lower cost -> higher prob of substitution). The point is, there's decades and many fields of psycholinguistics, and we can connect each of them with this question.

All of this is possible with our software that we published.

ADDTHIS:
Taking context into account is more than what we did. For instance, building on Zaromb 2006, you could imagine that the substitutions appear because the word preceding the substituted one appears in another dyad a lot more than this one, triggering a substitution (Zaromb's associative vs. contextual retrieval processes in recall).

ADDTHIS:
Soooooo... following literature on word lists (Zaromb and DRM):
- we could predict the new word in substitution? Take the strongest average association to words in the sentence.
- we could predict substituted word? Take the word following the one that triggers the new word.
Problems:
- we probably won't find the exact word, but one similar to it (even Zaromb can't predict the exact word, they don't try, they just check it comes from the right list). How to evaluate that?
- if computing LSA/LDA on the corpus (which probably isn't adapted because of the short sentence nature of the data -> topics = quote families), it's tautological unless you suppose substitutions have a negligible effect.
Explain that to the reviewer.

Again justify our approach w/ features by the shape of our data: few substitutions per cluster (avg. 9), and substitutions on relatively few clusters overall -> opposite situation to a few lists repeated through 50 subjects where frequency of transition has meaning. Here for each word, it's nearly one shot. So we have to categorize words (by using low number of features -> known features best) to get frequencies. From there, you can predict many many things, so better describe.


\end{new}

\section{Concluding remarks}\label{sec:conclusion}

\todo{\#14:
link to introduction discussion:
(1) this can be a model system,
(2) convergence can be looked for in any dimension, but that doesn't make a theory, so Epidemiology of Representations is all nice, but:
(3a) taken simplistically it predicts obviously simplistic stuff (all quotes CV. to a single quote),
(3b) taken more realistically (many dimensions in life) it gives some ideas, but it's not clear it's a core principle
(3c) we need more controlled investigation to fuel the discussion and see how relevant it is.
}

\begin{new}


ADDTHIS:
On the other side an enactive proposition which anthropologists like Ingold, in line with Mauss' works, are calling for \CN, is being developed by Froese, Di Paolo, and De Jaegher among others \CNs.

The question is also gaining relevance in other fields, as work in evo-devo and non-genetic inheritance is accumulating evidence not accounted for by the modern synthesis \CN;
these discoveries are creating demand for new or extended approaches to life evolution that unify its different levels, as well as creative empirical methods to test the predictions these approaches make \CN.

\end{new}

We aimed to contribute to the empirical understanding of representation transformation processes %\marginnote{fixed after Telmo saying: Is this really about knowledge transformation of more about representation transformations and the insight they provide over underlaying cognitive processes?}
 by studying a simple task where individuals are \emph{implicitly} trying to reproduce textual content. To some extent, our work amounts to a large \emph{in vivo} experiment where we appraise the impact of classically-influent psycholinguistic variables in the accuracy of the reproduction.
In more detail, we describe the joint properties of the substituted and substituting terms in the reformulation by individuals of a specific type of utterances (quotations). %--- in this sense we also diverge from psycholinguistic experiments that focus on ease of recall.

\todo{\#18: tone down claims about contractile: it's a possible hypothesis if this were the only process, but not observed with the mix of all other processes}

For each of the selected psycholinguistic variables, we demonstrate the existence of attractor values in the underlying variable spaces. More precisely, beyond the interpretation of our results for each variable, we notice that all variables remarkably exhibit a single attractor and are generally contractile --- as such, even though the observed convergence patterns only partially explain quotation evolution, we shed light on a class of phenomena which are susceptible to constitute a key element of a broader empirically-grounded, attractor-based theory of cultural evolution.

%Rather, we exhibit the bias of substitution, and that in this respect it not only provides a  we provide a fine description of the bias but also corresponds to an  ``input-output'' reformulation couple describing the joint properties of (substituted$\rightarrow$substituting) terms.

%We contend that our results provide some of the first bricks of an empirical \emph{fitness landscape} for the epidemiology of representations

%(age of acquisition, number of phonemes, ), it also emphasizes the importance of the semantic network structure (Wordnet: Pagerank, degree, clustering[, distance?]),


%\begin{itemize}
%\item new in the sense that it does not focus
%From a psycholingustic viewpoint,
