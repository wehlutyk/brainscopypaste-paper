% !TEX root = brainscopycut.tex
% ============================
\section{Methods} % =========
% ============================
\label{sec:protocol}

%In order to start bridging this gap, we set out to \emph{empirically} study public representation transformations at the microscopic level; 
%aiming to stay compatible with macroscopic-level studies of these public representations.
Quotations appeared to be a perfect candidate to propose a first \emph{in vivo} measure of low-level cognitive bias in a reformulation task. % as public representations.
First, they are usually cleanly delimited by quotation marks %(and often with HTML markup in web pages), 
which greatly facilitates their detection in text corpora.
Second, they stem from a unique ``original'' version, and could ideally be traceable back to that version.
Third, and most importantly, their duplication should \emph{a priori} be highly faithful, apart from cases of cropping: not only should transformations be of moderate magnitude, but when specific words are not perfectly duplicated, it is safe to assume that the variation is due to involuntary cognitive bias --- as writers may expect any casual reader to easily verify, and thus criticize, the fidelity to the original quotation.


We could therefore examine the individual substitution process at work when authors transform quotations, by examining the features of the substituted and substituting words in each substitution. To keep the analysis palatable, we focused on quotation transformations consisting in the \emph{substitution} of a word by another word (and only those cases) in order to unambiguously discuss single word replacements. 
To quantify those substitutions, we decided to associate a number of features to each word, the variation of which we can statistically study.

The next subsections describe the dataset and measures we used to assess this cognitive bias.
%Quotation evolution is therefore a perfect environment to measure cognition-induced transformations.%and relate those findings to macroscopic social dynamics.

\subsection{\emph{In vivo} utterances}

We used a quotation dataset collected by \citet{Leskovec09}, large enough to lend itself to statistical analysis.
This dataset consists of the daily crawling of news stories and blog posts from around a million online sources, with an approximate publication rate of 900k texts per day, over a nine-month period of time (from August 2008 to April 2009~---~\citealp{Leskovec09-url}).\footnote{Unfortunately, the original article~\citep{Leskovec09} does not provide additional details on the source selection methodology.}
Quotations were then automatically extracted from this corpus: each quotation is a more or less faithful excerpt of an utterance (oral or written) by the quoted person. For instance,
\begin{quote}
The Bank of England said, ``these operations are designed to address funding pressures over quarter-end.''
\end{quote}
Quotations were then gathered in a graph and connected according to their similarity: either because they differ by very few words (in that case, no more than one word) or because they share a certain sequence of words (in that case, at least ten consecutive words). We find for example the following variation of the above quote: \begin{quote}``these operations are \textbf{intended} to address funding pressures over quarter-end.''\end{quote}
A community detection algorithm was applied to that quotation graph to detect aggregates of tightly connected, that is sufficiently similar, groups of quotations~\citep[see][for more detail]{Leskovec09}.
This analysis yielded the final data we had access to, with a total of about \num{70000} sets of quotations; each of these sets allegedly contains all variations of a same parent utterance, along with their respective publication URLs and timestamps.

Manual inspection of this dataset revealed that it contains a significant number of everyday language quotations (such as ``it was much better than I expected'', ``did that just happen'', as well as many simple expletive-based sentences).
Their presence is largely due to random variations around casual expressions, while we are interested in transformations of news-related quotes causally linked to an original, identifiable utterance.
To filter them out, we exclude all quotes having less than 5 words long or lasting more than 80 days %\seb{it is asymmetrical...}
 (as well as quotes not written in English). If an entire cluster still lasts more than 80 days after this screening (because of short-lived but unrelated quotes far apart in time), we also exclude it.
% New filtering: 1051 substitutions out of 6172 mined. 45749 clusters. -- correct text with numbers and for new figures.
We eventually keep 45,749 clusters (out of 71,568; i.e. 63.9\%), containing a total of 127,778 unique quotes (out of 310,457; i.e. 41.2\%) making up about 2.43m occurrences (out of 8.16m, i.e. 29.8\%).\footnote{The significantly larger loss in occurrences indicates that, on average, the clusters we lose contain more occurrences than those we keep, which is expected for everyday language utterances.}
%We contend that the use of the unfiltered dataset would strongly jeopardize results related to linguistic evolution or information diffusion, 
Even if we lose some real event-related utterances which are present in clusters lasting more than 80 days (such as ``the city is tired of me and the organization and I have run our course together''), we check that our approach essentially fulfills its goals by manually coding a random subsample of 100 excluded clusters: a solid 71\% appear to be entirely irrelevant to our analysis (everyday language rather than quotations), and all but one of the remaining clusters were of relevance to the protocol \TB{set out below.}% in Sec.~\ref{sec:model}.


\subsection{Word-level measures}

\subsubsection{Psycholinguistic indices}

We first introduce some of the most classical psycholinguistic measures on words.

\begin{APAitemize}
    \item \textbf{Word frequency}: the frequency at which words appear in our dataset, known to be relevant for both recognition and recall~\citep{gregg1976word},
    \item \textbf{Age of Acquisition}: the average age at which words are learned~\citep[obtained from][]{Kuperman12}, known to have different effects than word frequency~\citep{morrison1995roles,dewhurst1998separate},
    \item The average \textbf{Number of Phonemes} and \textbf{Number of Syllables} for all pronunciations of a word (obtained from the Carnegie Mellon University Pronouncing Dictionary, \citealp{Weide98})\footnote{The CMU Pronouncing Dictionary is included in the NTLK package~\citep{Bird09}, the natural language processing toolkit we used for the analysis.} as a proxy to word production cost,
    \item The average \textbf{Number of Synonyms} for all meanings of a word~\citep[obtained from][]{WordNet10} as an \emph{a priori} indicator of how easy it would be to replace a word.
\end{APAitemize}

%We also considered grammatical types within quotations by detection of \emph{Part-of-Speech} (POS) categories, using the Penn TreeBank Project typology~\citep{Santorini90} and thereby distinguishing verbs, nouns, adjectives and adverbs. The results were however extremely similar across the various categories, exhibiting no specific effect of words belonging to different POS categories. \rk{See \#8 for this fact-check}

The number of synonyms is related to a notion of the word connectivity in a semantic network.  To go a bit further in this direction, we appraise the possible role of network-based variables which have received special attention in the recent related literature, following the blooming interest in networks from many disciplines over the last decade. 

\medskip
%, we thus considered more recently studied variables based on semantic network properties.
We relied on the ``free association'' (FA) norms collected by \citet{Nelson04} which naturally embed information on the idea association process underlying transformation of quotations. FA norms record the words that come to mind when someone is presented with a given cue% (that is the ``free association'' task)
. As \citet{Nelson04} explain, ``free association response probabilities index the likelihood that one word can cue another word to come to mind with minimal contextual constraints in effect.''
%Following \citet{Griffiths07}, we first consider the directed weighted network formed by the association norms, that is the network where words are nodes and edges are directed from cue to associated word, with a weight equal to the probability of that target word being produced when this particular cue was presented.
% \rk{we're in fact using the unweighed version of the network. Why?}
%Following \citet{Griffiths07}, we first build a directed unweighted network based on association norms, where words are nodes and edges are directed from cue to target word whenever a target word is being produced when this particular cue word was presented.
Following \citet{Griffiths07}, we first build a directed unweighted network based on association norms, where nodes are words and edges are directed from cue to target word whenever the considered target word was produced in response to the considered cue word.
This network is of particular interest since it measures the \emph{in-vitro forced-choice} version of a substitution whereas the data we analyze is the \emph{in-vivo spontaneous} version of what we otherwise hypothesize to be the same process.

Three standard network-based measures are to be used on the FA network% \rk{adapt once the weighing question (\#8) is settled}
:

\begin{APAitemize}
    \item \textbf{Degree centrality}, measured by the number of cues for which a given word is triggered as a target, and a corresponding generalized measure, node \emph{pagerank}~\citep{Page99}, which has already been used on the FA network by \citet{Griffiths07}.
    In the present case these two polysemy-related measures are quasi-perfectly correlated. %, and measure polysemy by taking into account the structure of the entire network.
    %However in the present case there is a quasi-perfect correlation between node incoming degree and node \emph{pagerank}~\citep{Page99}, which will lead us to favour the latter later on. Word pagerank on the FA network had already been used by~\citet{Griffiths07}; it may be interpreted as a generalized and recursive measure of word polysemy: central nodes in the pagerank sense are words often selected as targets when presented with cues themselves often selected as targets, and so on recursively.
    \item \textbf{Betweenness centrality}, another measure of node centrality describing the extent to which a node connects otherwise remote areas of the network~\citep{free:set}.
    This quantity tells us if some words behave like unavoidable waypoints on association chains connecting one word to another.
    \item \textbf{Clustering coefficient}, which measures the extent to which a node belongs to a local aggregate of tightly connected nodes~\citep{watt-coll}, computed on the undirected version of the FA network.\footnote{The Clustering coefficient is formally defined as the ratio between the number of actual versus possible edges between a node's neighbors.}
    This tells us if a word belongs more or less to a local aggregate of equivalent words (from a ``free association'' point of view).
\end{APAitemize}

\subsubsection{Variable correlations}

An important question arises concerning the possible correlations between all the variables we use.

\begin{figure}[!th]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/correlations-filter1.png}
    \caption{Spearman correlations in the initial set of features}
    \label{fig:feature-corrs-initial}
\end{figure}

The number of phonemes and the number of syllables naturally exhibit a strong linear correlation ($.8$).
Our analysis showed clearer results with number of phonemes over number of syllables, which is consistent with \citet{nick-diss}, and we therefore chose to only present results for the former.

Age of acquisition is a key variable which appears as a usual suspect in psycholinguistic studies.
Despite it being usually difficult to disentangle from many of the other variables, it is known to have independent effects, which is consistent with what we see on Fig.~\ref{fig:feature-corrs-initial}: age of acquisition has a limited correlation to the other variables (absolute value not above $.39$ if we exclude the number of syllables and the network properties), leading us to keep the variable in the rest of the analysis.

Frequency and number of synonyms both have relatively low levels of correlation to the other variables (excluding again the network properties); we therefore also keep them in the rest of the analysis.

\bigskip
Network centrality properties, on the other hand, are strongly dependent on one another.
As mentioned earlier, degree centrality and pagerank have a very strong correlation ($.85$), and are also redundant with betweenness centrality (with correlation levels at $.75$ and $.68$ respectively).
Furthermore, the three variables are also strongly related to age of acquisition, which leads us to keep the latter as the sole indicator for centrality. This may trigger a chicken-and-egg issue where a strong centrality may be due, or be the result, of an early age of acquisition; in any case, the age of acquisition seems to partially capture centrality-based network properties.

Conversely, clustering coefficient exhibits low correlation levels with all the variables we kept (maximum absolute value $.38$), leading us to include it in the rest of the analysis.

The final set of variables we consider, as well as their cross-correlations, can be seen in Fig.~\ref{fig:feature-corrs-filtered}.\footnote{Note that feature values stem from different datasets which do not always encode the same words.
Indeed, we have data on frequency for about 22.6k words, on age of acquisition for 30.1k words, on number of phonemes for 123.4k words, number of synonyms 111.2k, and clustering coefficient 5.7k words.
Quite often then, not all features are available for all words in our dataset; % are encoded in only a subset of the features we use (if any at all); 
however this is not problematic since the analysis is done on a per-feature basis, and not all words need be encoded in all features.}

\begin{figure}[!th]
    \centering
    \includegraphics[width=0.6975\linewidth]{images/computed-figures/correlations-filter2.png}
    \caption{Spearman correlations in the filtered set of features}
    \label{fig:feature-corrs-filtered}
\end{figure}


\subsection{Substitution model}
%\subsubsection{Temporal binning}
\label{sec:temporal-binning}\label{sec:model}

We finally need a substitution detection model, for the utterance data we use presents a challenge: quote-to-quote transformations, and much less substitutions, are not explicitly encoded in the dataset. More precisely, each set of quotations bears no explicit information about either the authoritative original quotation, or the source quotation(s) each author relied on when creating a new post and reproducing (and possibly altering) that source.
We thus face an inference problem where, given all quotations and their occurrence timestamps, we should estimate which was the originating quotation for each instance of each quotation.

We therefore model the underlying quotation selection process by making a few additional assumptions. % which let us define quote-to-quote substitutions from the available data.
The main issue is deciding whether a later occurrence is a strict copy of an earlier occurrence, or a substitution of an even earlier occurrence, or perhaps even a substitution or copy from quotes appearing outside the dataset, that is from a source external to the data collection perimeter.

Let us give an example: say the quotation ``These accusations are false and \textbf{absurd}'' ($q$) appears in a blog on January 19, and the slightly different quotation ``These accusations are false and \textbf{incoherent}'' ($q'$) appears in other blogs twice on the 20th and once on the 21st of January.
If $q$ was sufficiently prominent when $q'$ first appeared, we can safely assume that the first author of $q'$ on the 20th based himself on $q$ as is shown in Fig.~\ref{fig:substitution-temporal-binning-a}.
But what about the second and third occurrences of $q'$, on the 20th and 21st?
Should we consider them to be substitutions based on $q$ %(i.e. re-creations of $q'$ by a new instance of the substitution process that brought from $q$ to $q'$ in the first place) 
or accurate reproductions of the previous occurrences of $q'$? (Options shown in Fig.~\ref{fig:substitution-temporal-binning-a}.)

\begin{figure}[h]
    \centering
    \subfloat[Possible paths from occurrence to occurrence]{
	    \def\svgwidth{\linewidth}
	    \small
	    \input{images/substitution-temporal-binning-a.pdf_tex}
	    \label{fig:substitution-temporal-binning-a}
	}
	\hfill \\
	\subfloat[Binned quotation family with majority rule]{
	    \def\svgwidth{\linewidth}
	    \small
	    \input{images/substitution-q_max.pdf_tex}
	    \label{fig:substitution-q_max}
	}
	\caption{{\bf Temporal binning of quotation families.} $q$ and $q'$ are two versions of a quotation belonging to the same cluster.  In the bottom panel (b), $q'$ holds the majority in the 3rd bin and is considered the unique basis for the last occurrence of $q$ (in the 4th bin). This is despite the fact that $q$ also appears in bin~3 alongside $q'$, and despite it having appeared earlier at the very beginning of the quotation family (indeed in the situation shown in Fig.~\ref{fig:substitution-q_max}, this seems to be the most likely scenario). Conversely, if $q$ had been the most frequent quote in bin~3, the last occurrence of $q$ in bin~4 would have been considered a faithful copy of the occurrence of $q$ in bin~3.}
    \label{fig:substitution-temporal-binning}
\end{figure}

To settle this question we group quote occurrences into fixed bins spanning $\Delta t$ days (1 day in the implementation), each one representing a unit of time evolution.
When a quotation $q'$ appears in bin $t+1$, it is counted as a substitution if it differs from the most frequent quote $q$ of the preceding bin $t$ (or a substring thereof) by only one word. If not, $q'$ is not considered to be an instance of substitution.  %We assume here that quotes are based on the most frequent quote of the preceding bin (\hbox{vs.} all the other quotes in that bin).  
Note that these assumptions are admittedly a subset of a much wider set of possibilities, each leading to alternative substitution inferences.\footnote{In particular, the criterion of the most frequent quote in the preceding bin may be replaced with the most frequent quote overall, or the oldest quote; time can be sliced into fixed bins as is done here, or kept fine-grained by using sliding bins.}
It is however not feasible to try them all and, for the sake of simplicity, we decided to go with a sensible set of assumptions, and stick to them without trying alternative options.
%These various flavors of an ideal substitution detection model essentially change whether occurrences are considered as substitutions from another quote, repetitions of the original quote, or introduction of information external to the dataset.
%\TB{We identified and implemented eleven other such models, and they all yielded essentially the same results.} \rk{T: I would prefer a bit more detail here. Maybe on supp. mats.? What does “essentially the same” mean? This could cause concern to reviewers.}

\medskip
Put shortly, such a model defines how many times quote occurrences can be counted as substitutions: in Fig.~\ref{fig:substitution-q_max}, occurrences of $q'$ on the 20th are counted as substitutions, whereas the occurrences on the 21st are not.  In practice, from the 2.43m initial occurrences spread into 45,749 classes of quotes, with significant redundancy (many quotes are indeed simple duplicates), we manage to mine 6,172 real substitutions obeying to this model. From these substitutions we remove those featuring stop words, minor spelling changes (e.g. center/centre, November/Nov, Senator/Sen), abbreviations, spelled out numbers; this eventually yields 1,051 valid substitutions.

%Let us illustrate this ``majority'' rule by going back to the example described in Section~\ref{sec:temporal-binning} and extending it, in Fig.~\ref{fig:substitution-q_max}.

\section{Results}\label{sec:results}

We may now use this substitution model to formulate a family of psycholinguistic hypotheses describing the role of each feature in the accuracy of the reformulation.  To this end, we build two main observables for each word feature.  
First, we measure the susceptibility for words to be the target of a substitution in a quote, knowing that there has been a variation, in order to show which semantic features are the most likely to ``attract'' a substitution under this condition. Second, we measure the change in word feature upon substitution, looking at the variation of a given feature between start and arrival words.

Note that since we only consider substitutions and not faithful copies, we measure the features of an alteration \emph{knowing that there has been an alteration}, and we do not take invariant quotations into account.
Indeed, in the former case we know there has been a human reformulation, whereas in the latter case it is impossible to know whether there has been perfect human reformulation or simply digital copy-pasting of a source (``{\sc Ctrl-C}/{\sc Ctrl-V}'').
Furthermore, perfect human reformulation possibly involves different practices than those involved in alteration ---~for instance drafting before publishing, double-checking sources, proof-reading~--- and may not be representative of the cognitive processes at work during alteration.
The two situations are different enough to be studied separately, and we focus here on the latter.

\subsection{Susceptibility}

We say that a word is \emph{substitutable} if it appears in a quote which undergoes a substitution, whether that substitution operates on that word or on another one.
Word substitution susceptibility is computed as the ratio of the number of times $s_w$ a word is substituted to the number of times $p_w$ that word appears in a substitutable position, that is $\sfrac{s_w}{p_w}$. {In other words, it measures how often a word $w$ actually gets substituted, compared to how often it could have been substituted (because it appears in quotes undergoing substitution)}.

Now, for a given feature $\phi$, we obtain the mean susceptibility $\sigma_{\phi}(f)$ for the feature value $f$ by averaging this ratio over all words such that $\phi(w) = f$, that is% (only taking into account words that are substituted at least once)
:

$$\sigma_{\phi}(f) = \left< \frac{s_w}{p_w} \right>_{\left\lbrace w | \phi(w) = f \right\rbrace}$$

Put shortly, susceptibility focuses on the selection of start words involved in substitutions, measuring the effect of features at the moment preceding the substitution when it is not yet known which word in the quotation will be substituted.

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/feature_susceptibilities.png}
    \caption{\textbf{Substitution susceptibility:} average susceptibility to substitution versus average feature value of a candidate word for substitution, with 95\% asymptotic confidence intervals.
    The heatmap on the lower-right shows the joint effect of Number of synonyms and Number of phonemes on susceptibility, averaged over the respective single-variable ranges, with sample size (word numbers) in parentheses.}
    \label{fig:feature-susceptibilities}
\end{figure*}
\medskip
Results for this measure are gathered in Fig.~\ref{fig:feature-susceptibilities}. They first show an obvious strong effect of Word frequency: the more frequent a word, the less likely it is to attract substitutions.
Indeed, susceptibility goes from $.33$ for low-frequency words down to nearly 0 for very high-frequency words.
To make things clear, this value of $.33$ means that low-frequency words, when present in a quote undergoing a substitution, are the ones being substituted 33\% of the time on average.

The other features --- Age of acquisition, Number of phonemes, Clustering coefficient and Number of synonyms --- do not seem to exhibit any particularly significant effect on susceptibility.
{If we set aside the values for low Number of phonemes}, for each of these features it is indeed possible to draw a constant line which always remains within the respective confidence intervals.
If these variables have an effect, it is by no means as strong as it is for Word frequency.
This is remarkably clear for Clustering coefficient and Age of acquisition, where susceptibility values remain within quite small intervals (respectively $[.13-.18]$ and $[.16-.20]$).
{We may notice a slight effect for the lowest values of Number of synonyms and Number of phonemes, where the mean susceptibility is almost half as high as the average of the other values (respectively $.09$ vs. $.16$, and $.11$ vs. $.17$).}
Keeping in mind the poor statistical significance of this effect, we could still wonder if the shortest words and words with fewest synonyms are significantly less susceptible to substitution.
To further examine this phenomenon, we plotted the two-dimensional map of susceptibility values for these two features (see heatmap at the bottom right of Fig.~\ref{fig:feature-susceptibilities}).
%\TG{TBF: [[We see that outlier values (the two darkest cells) are both due to cells where the number of items is only slightly above the significance threshold (11 items, while we decided to cut at 10).]]}
%\TG{TBF: [[If we focus on cells based on at least several dozens of words]]} 
Values tend to navigate around the mean value ($.16$), even if there are a few outlier cells, yet with little obvious regularity (except for a low number of synonyms, consistently with the unidimensional graph). {On the whole, this makes it relatively hard to draw any conclusion as regards the direction of an effect, except for the least populated value ranges (which as a result are also less significant).}
%\TG{TBF: [[This confirms the fact that the slight late increases observed for Age of acquisition and Number of phonemes are rather non-significant.]]}

%\TB{This class of words corresponds to \todo{} [\TB{highly specialized words? domain-specific? a hard limit on too complicated words?}]}
%Age of acquisition and Number of phonemes delineate two categories of words: both features have little to no significant effect on susceptibility for low- to mid-valued words, but very high-valued words behave differently and tend to be more substituted (clearly for high Number of phonemes, and only as a tendency for high Age of acquisition).
%These high-valued words also have low occurrence frequencies, which corresponds to the slope change in the frequency curve between extreme low frequency words and mid- to high-frequency words. \rk{check this with a plot of freq vs. clustering and freq vs. AoA, or simply plot of frequency for the high-valued words for AoA and CC.}

All in all, apart from Word frequency and despite some local tendencies, {in general} these results do not allow us to conclude either to a marked effect %or to no effect 
of the selected psycholinguistic features on substitution susceptibility.
We may therefore globally assume that substitution targets are chosen in a more or less uniform way with respect to these features.

% plus ou moins choisies uniformément (modulo les réserves exhibées en 4.1), on peut montrer en quoi elles sont modifiées Finally the results for Clustering coefficient and Number of synonyms, despite some tendencies, do not allow us to conclude either to an effect or no effect of those features on substitution susceptibility.

\subsection{Variation}

We can thus show how words are modified once we know they are substituted, that is how their features are modified by said substitution.
Considering a word $\wstart$ substituted for $\warrival$, we measure how the feature of $\wstart$ varies when it is replaced with $\warrival$, that is we look at $\phi(\warrival)$ as a function of $\phi(\wstart)$. 
Averaging this value over all start words such that $\phi(w) = f$ yields the mean variation for that feature value~$f$, that is:\footnote{To avoid possible autocorrelation effects due to substitutions belonging to the same cluster (which are likely not statistically independent and may lead to overly optimistic confidence intervals), we first average substitutions over each cluster, by considering the average of arrival word features for a given start word.}
$$\nu_{\phi}(f) = \left<\phi(\warrival)\right>_{\left\lbrace \wstart\rightarrow\warrival | \phi(\wstart) = f \right\rbrace}$$

Of prime interest is the comparison of the value of $\nu_{\phi}(f)$ with respect to $f$, as it shows whether there is an attraction (or a repulsion) effect towards (respectively from) some values of each feature.
In other words, plotting the $y=x$ line, we can see if substitutions tend to converge towards some typical value of a word feature or not --- as is classically done in the study of dynamical systems.

We also introduce a null hypothesis $\mathcal{H}_0$ to compare the actual variation of a word's feature to its expected variation, assuming the arrival word $\warrival$ was randomly chosen from the whole pool of words available in the dataset for that feature.\footnote{For instance, when considering the feature ``Clustering coefficient'', the arrival word is randomly chosen among words present in the dataset of FA norms.}
%\TB{randomly chosen from the whole pool of words in the dataset from which the feature is built (e.g. for Clustering coefficient: randomly chosen in the pool of words in the Free Association norms)}.\marginnote{C: ici on est bien d'accord que le pool of FA words c'est tout le set de mots, pas juste les voisins? la formulation est un peu ambigüe. S: oui et non. Oui: c'est pas juste les voisins. Non: le pool dépend de la feature, c'est pas juste FA. Il y avait une erreur, j'ai reformulé pour être plus clair.}
In this case, since $\phi(\warrival)$ becomes a constant value in the above averaging (by definition $\warrival$ does not depend on $\wstart$ anymore),  the baseline variation under $\mathcal{H}_0$ may be rewritten as:\footnote{We additionally considered an alternative null hypothesis, denoted $\mathcal{H}_{00}$, where the arrival word is randomly chosen \emph{among immediate synonyms of the start word}, that is an arrival word chosen among semantically plausible though still random words. In this case $\warrival_{00}$ does depend on $\wstart$. Our conclusions hold under this second null hypothesis, so for the sake of clarity we chose to keep the simpler~$\mathcal{H}_0$.}
$$\nu_{\phi}^0 (f) = \left<\phi\right>$$
%We thereby obtain the mean variation of feature for each start feature value, comparing the variations to a situation where arrival words are chosen randomly.

This approach yields a fine-grained view of how word features evolve upon substitution, on average, with respect to 
\begin{seriate}
\item the original feature (\hbox{vs.} $y=x$) and 
\item a random arrival (\hbox{vs.} $\nu_{\phi}^0$).
\end{seriate}
\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/feature_variations-binned.png}
    \caption{\textbf{Feature variation upon substitution:} $\nu_\phi$, average feature value of the appearing word as a function of the feature value of the disappearing word in a substitution, with 95\% asymptotic confidence intervals.
    The overall position of the curve with respect to the dashed line representing $\mathcal{H}_0$ (constant $\nu_{\phi}^0$) indicates the direction of the cognitive bias.
    The intersection with $y = x$ marks the attractor value.
    %The fact that all curves have slopes smaller than 1 means that the substitution operation is contractile on average: each feature will converge towards its own specific asymptotic range.    
    }
    \label{fig:feature-variations}
\end{figure*}

\medskip
Results are gathered in Fig.~\ref{fig:feature-variations}.
We can do a first striking observation: all graphs show the existence of a unique intersection of $\nu_{\phi}$ with $y=x$, while the slope of $\nu_{\phi}$ is smaller than 1, independently of the feature considered.
In other words, beyond individual variation patterns, the substitution process is contractile for all the features, and each of them therefore exhibits a unique attractor.
Second, the comparison with $\nu_{\phi}^0$ shows that there are two classes of attractors, depending on whether:
\begin{APAenumerate} 
\item there is a triple intersection (of $y=x$, $\nu_{\phi}^0$ and $\nu_{\phi}$);
\item or $\nu_{\phi}$ always remains above or below $\nu_{\phi}^0$.
\end{APAenumerate}
The first class (Number of phonemes and Number of synonyms) are features for which the substitution process only brings words slightly closer to $\nu_{\phi}^0$, and no uniform bias can be observed.
%\TB{(furthermore, $\mathcal{H}_{00}$ stays inside the confidence intervals of $\nu_{\phi}$, confirming that these two features are irrelevant for the substitution process)}.
%\rk{Cam: On vire ou bien?}


On the other hand, the second class (comprising Word frequency, Age of acquisition, and Clustering coefficient) are features for which the substitution process has a clear bias, positive or negative, with respect to the purely random situation ($\mathcal{H}_0$).

Word frequency, with $\nu_{\phi}$ always significantly above $\nu_{\phi}^0$, exhibits a strong bias towards more frequent words. This, in turn, is consistent with the hypothesis that substitution is a recall process, since common words are favored over awkward ones, while it goes against the idea that it could be a familiarity process, where awkward terms would be favored.
%\cam{je crois qu'on peut éviter l'inférence inverse en ne disant pas "confirms" (c'est exagéré en effet) mais en disant juste que c'est cohérent avec un processus mais pas l'autre; j'ai changé le wording}
% , Mais est-ce que c'est pas une inférence inverse que de dire ceci? i.e. on sait qu'une tâche "familiarity/recognition" implique un biais en faveur des mots awkards, et qu'une tâche "recall" implique un biais en faveur des mots fréquents, mais on peut pas vraiment tirer de conclusions en utilisant la réciproque, si?}.
%However, the detailed variations of the Word frequency curve, despite an inflection for high-frequency words, do not seem to follow any significant pattern.\cam{Je serais pour supprimer cette phrase purement factuelle et pas très clear-cut non plus}


Age of acquisition and Clustering coefficient, on the other hand, exhibit a clear negative bias for the substitution process. Both curves are significantly below their respective $\nu_{\phi}^0$ values, which is consistent with the literature on recall: words learned earlier and words with lower clustering coefficient are easier to produce than average~\citep{nelson2013activation,Zevin02}.
Clustering coefficient has the additional particularity that, on average, the destination word does not depend on the start word; that is on average, substitutions will always produce words with a clustering coefficient around $\exp(-2.4) \simeq .1$.

To make things concrete, here is an example substitution taking place in the dataset.
At the end of January 2009, many media websites reported the following quote,

\begin{quote}
    ``The massive economic upheaval being experienced across the globe is sparing no one in the consumer electronics world.''
\end{quote}
and a smaller number of media websites, and blogs, reported the following,
\begin{quote}
    ``The massive economic upheaval being experienced across the \textbf{world} is sparing no one in the consumer electronics world.''
\end{quote}
The word \emph{globe} is acquired at an average of 6.5 years old, appears about 3.5k times in the dataset, and has a Clustering coefficient of $.24$.
The word it was replaced with, \emph{world}, is acquired on average at 5.3 years old, appears about 146k times in the dataset, and has a Clustering coefficient of $.05$. (Both words have four phonemes.)
Such a change, though minor in appearance, is a typical example of alteration along the lines shown by our results.

%globe (age 6.5, phonemes 4.0, freq 8.18, cc -1.42, susceptibility 1.0)
%world  [age 5.32, phonemes 4.0, freq 11.89, cc -2.95, susceptibility 0.272727272727]

\medskip
We thus observe a clear convergence pattern for each feature, with two different classes corresponding to the psychological relevance of each feature for the substitution process.
Taken as a dynamical system where substitutions are repeatedly applied, Number of phonemes and Number of synonyms will simply converge towards their average value in the FA corpus (i.e. $\nu_{\phi}^0)$, while Word frequency, Age of acquisition and Clustering coefficient, consistent with the literature, will converge towards significantly biased values indicated by the intersection with $y = x$ (respectively, a frequency of $\exp(9.1) \simeq 9000$, an acquisition age slightly below 8, and a Clustering coefficient of $.1$).

