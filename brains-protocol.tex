% !TEX root = brainscopycut.tex
% ============================
\section{Methods} % =========
% ============================
\label{sec:protocol}

\todo{\#20: check text/flow/definitions for clarity against Gureckis' edited pdf}

\newtext{We rely on a text corpus made of quotations extracted from online blog posts, and focus on their evolution.}
\newtext{Indeed} quotations appeared to be a perfect candidate to propose a first measure of \newtext{automatic} cognitive bias in \newtext{cultural transmission}.
First, they are usually cleanly delimited by quotation marks which greatly facilitates their detection in text corpora.
Second, they stem from a unique original version, and are ideally traceable back to that version.
Third, and most importantly, their duplication should \emph{a priori} be highly faithful, apart from cases of cropping:
not only should transformations be of moderate magnitude, but when specific words are not perfectly duplicated, it is safe to assume that the variation is due to involuntary cognitive bias --- as writers may expect any casual reader to easily verify, and thus criticize, the fidelity to the original quotation.

We could therefore study the individual transformation process at work when authors alter quotations, by examining the modified words in each transformation.
\newtext{Since our approach is exploratory however, we do not know at the outset which precise effect of cognitive bias we are looking for.
Indeed the data we use does not come from a controlled experiment in the laboratory, designed to elicit a particular effect: they are recordings of real life interactions, with all the complexity and uncertainty of conditions this entails.
%In this study, therefore, we did not try to predict and explain in detail the cognitive processes responsible for transformations
%\todo{, as this would be akin to a drink from the firehose. \sf [Cam: supprimer? potentiellement un excès d'autoflagellation -- en fait on devrait pouvoir dire simplement: ``The prediction and detailed explanation of the cognitive processes responsible for transformations is outside of the scope of this study'', probablement après la fin de la phrase suivante (``of a larger complexity (the detailed prediction and deconstruction of the cognitive processes etc. outside the scope etc. further research)'' mais même là cette modestie pourrait plutôt être de mise dans la conclusion? ou bien il s'agit d'une critique directe d'un reviewer ?  Un peu pareil pour ``our approach is exploratory'' (que j'ai laissé au nom de l'ambiguïté d'exploratoire qui veut aussi bien dire ``premier brouillon'' que ``data mining'') et ``this first study'' (où j'ai enlevé le `first' car trop ``bon c'est à moitié fini mais on soumet quand même'' ;) ]}
Our goal, therefore, is to show that such effects exist and are measurable even if they are part of a larger complexity (the detailed prediction and deconstruction of the cognitive processes responsible for them being left to further research).
%\todo{That is, we aim to prove first a relatively weak hypothesis before trying stronger ones. [Cam: idem, je supprimerais celle-là]}
If this is confirmed, we will have successfully applied laboratory analyses to out-of-laboratory data, opening a path to explanations of actual (\hbox{vs.} simulated) cultural evolution with tools from cognitive science.
As explained in the previous section, this is the reason we chose to use measures that can aggregate over all the transformations in the data set.}
\todo{this last sentence is unclear or not useful}

To keep the analysis \newtext{tractable}, we focused on quotation transformations consisting in the \emph{substitution} of a word by another word (and only those cases) in order to unambiguously discuss single word replacements.
\newtext{This restriction also allows us to more reliably infer the information that is missing in our data set, as explained further down (see "Substitution model").}
To quantify those substitutions we decided to associate a number of features to each word, the variation of which we can statistically study.

The next subsections describe the data set and the measures we used to assess this cognitive bias.

\subsection{\emph{In vivo} utterances}

We used a quotation data set collected by \citet{leskovec_meme-tracking_2009}, large enough to lend itself to statistical analysis.
This data set consists of the daily crawling of news stories and blog posts from around a million online sources, with an approximate publication rate of 900k texts per day, over a nine-month period of time from August 2008 to April 2009 (\citealp{leskovec_memetracker:_2009}).\footnote{
The original article~\citep{leskovec_meme-tracking_2009} does not provide further details on the source selection methodology.
}
\newtext{The authors automatically extracted quotations} from this corpus.
Each quotation is a more or less faithful excerpt of an utterance (oral or written) by the quoted person; for instance:
\begin{quote}
The Bank of England said, "these operations are designed to address funding pressures over quarter-end."
\end{quote}

\newtext{Then, the authors gathered quotations in a graph and connected each pair that differed by no more than one word or that shared at least ten consecutive words (they tested this procedure with a number of different parameters, see~\citealp{leskovec_meme-tracking_2009}, for more details).}
We find for example the following variation of the above quote:
\begin{quote}
"these operations are \textbf{intended} to address funding pressures over quarter-end."
\end{quote}
\newtext{Next, they applied a community detection algorithm} to that quotation graph to detect aggregates of tightly connected, that is sufficiently similar, groups of quotations~\citep[see again][for more details]{leskovec_meme-tracking_2009}.
This analysis yielded the final data we had access to, with a total of about \num{70000} sets of quotations; each of these sets ideally contains all variations of a same parent utterance, along with their respective publication URLs and timestamps \newtext{(since the procedure cannot be perfect, sets of quotations contain occasional rogue unrelated variations that should have been discarded or assigned to another set)}.

Manual inspection of this data set revealed that it contains a significant number of everyday language quotations (such as ``it was much better than I expected'', ``did that just happen'', as well as many simple expletive-based sentences).
Their presence is largely due to random variations around casual expressions, while we are interested in transformations of news-related quotes causally linked to an original, identifiable utterance.
To filter them out, we exclude quotes with less than 5 words or \newtext{whose occurrences span more} than 80 days (indicating causally unrelated occurrences), as well as quotes not written in English.
\newtext{Clusters that are emptied by this procedure are therefore excluded.}
If, after this screening, a cluster's occurrences still span more than 80 days (because of short-lived but unrelated quotes far apart in time), we also exclude it.
\newtext{We eventually keep 50,427 clusters (out of 71,568; \hbox{i.e.} 70.5\%), containing a total of 141,324 unique quotes (out of 310,457; \hbox{i.e.} 45.5\%) making up about 2.60m occurrences (out of 7.67m; \hbox{i.e.} 33.9\%).\footnote{
The significantly larger loss in occurrences indicates that, on average, the clusters we lose contain more occurrences than those we keep, which is to be expected for everyday language utterances.
}
Even if we lose some real event-related utterances which are present in clusters lasting more than 80 days (one such lost quote, for instance, is "the city is tired of me and the organization and I have run our course together"), we check that our approach fulfills its goals by coding a random sub-sample of 100 clusters:
35 of them are rejected by the filter, with 15 false negatives (rejected clusters that should have been kept) and 9 false positives (clusters kept when they should have been rejected), giving a precision score of 0.862 and a recall score of 0.789.
Furthermore, all but one of the 9 false positives are left with a single non-rejected quote, meaning those clusters are ignored by our substitution analysis; this brings the effective precision of our filter to 0.982.}\footnote{
\newtext{A similar analysis was made for language detection, which is part of the cluster filtering:
out of 100 randomly sampled quotes, 17 are rejected because their detected language is not English, with no false positives and 6 false negatives, giving a precision score of 1 and a recall score of 0.933.
Of the 6 false negatives, 4 had less than 5 tokens and would have been excluded by the cluster filter anyway.
}}


\subsection{Word-level measures}

\subsubsection{Lexical features}

We first introduce some lexical measures on words.

\begin{APAitemize}

    \item \textbf{Word frequency}: the frequency at which words appear in our data set, known to be relevant for both recognition and recall~\citep{gregg_word_1976},

    \item \textbf{Age of Acquisition}: the average age at which words are learned~\citep[obtained from][]{kuperman_age--acquisition_2012}, known to have different effects than word frequency~\citep{morrison_roles_1995,dewhurst_separate_1998},

    \item \newtext{\textbf{Phonological} and \textbf{Orthographic Neighborhood Density}~\citep[obtained from][]{marian_clearpond:_2012}, also known to be relevant for word production~\citep{garlock_age--acquisition_2001},}

    \item The average \textbf{Number of Phonemes} and \textbf{Number of Syllables} for all pronunciations of a word (obtained from the Carnegie Mellon University Pronouncing Dictionary, \citealp{weide_cmu_1998})\footnote{
    The CMU Pronouncing Dictionary is included in the NTLK package~\citep{bird_nltk_2009}, the natural language processing toolkit we used for the analysis.
    },
    \newtext{as well as \textbf{Number of Letters}}, as a proxy to word production cost,

    \item The average \textbf{Number of Synonyms} for all meanings of a word~\citep[obtained from][]{wordnet_princeton_2010} as an \emph{a priori} indicator of how easy it would be to replace a word.

\end{APAitemize}

\newtext{We also consider grammatical types within quotations by detecting \emph{Part-of-Speech} (POS) categories with TreeTagger~\citep{schmid_probabilistic_1994}; we distinguish between verbs, nouns, adjectives, adverbs, and stopword-like words.}

\medskip

\newtext{Aside from these raw features, the systemic dimension of vocabulary~\citep{cornish_systems_2013} has led authors to develop measures based on the full topology of networks built from free association data or phonological similarity.
Several such measures have been shown to be involved in recall, recognition, and naming tasks~\citep{nelson_how_2013,chan_network_2010,griffiths_google_2007}.}

\newtext{To compute those features} we relied on the free association (FA) norms collected by \citet{nelson_university_2004}, which record the words that come to mind when someone is presented with a given cue.
As \citet{nelson_university_2004} explain, "free association response probabilities index the likelihood that one word can cue another word to come to mind with minimal contextual constraints in effect."
\newtext{Similar to what \citet{griffiths_google_2007} did, we first considered the directed \newtext{weighted} network formed by association norms, where nodes are words and edges are directed from cue to target word, with a weight equal to the association strength (that is the probability of that target word being produced when this particular cue is presented).
This network is of particular interest since it lets us define features that reflect the associations driving false memories in word lists~\citep{deese_prediction_1959}, a phenomenon which may be involved in the transformation of quotations.}

We used three standard measures on the FA network:

\begin{APAitemize}

    \item \textbf{\newtext{Incoming} degree centrality}, measured by the number of cues for which a given word is triggered as a target, and a corresponding generalized measure, node \textbf{Pagerank}~\citep{page_pagerank_1999}, which has already been used on the FA network by \citet{griffiths_google_2007}.
    In the present case these two polysemy-related measures are quasi-perfectly correlated.\footnote{
    \newtext{Note that in-degree does not take the weights of links into account, as it counts 1 for each incoming link.
    Pagerank on the other hand, does take the weights into account.}
    }
    %, and measure polysemy by taking into account the structure of the entire network.
    %However in the present case there is a quasi-perfect correlation between node incoming degree and node \emph{pagerank}~\citep{Page99}, which will lead us to favour the latter later on. Word pagerank on the FA network had already been used by~\citet{Griffiths07}; it may be interpreted as a generalized and recursive measure of word polysemy: central nodes in the pagerank sense are words often selected as targets when presented with cues themselves often selected as targets, and so on recursively.

    \item \textbf{Betweenness centrality}, another measure of node centrality describing the extent to which a node connects otherwise remote areas of the network~\citep{freeman_set_1977}.
    This quantity tells us if some words behave as unavoidable waypoints on association chains connecting one word to another.\footnote{
    \newtext{For this measure, weights are interpreted as inverse cost:
    the stronger a link, the easier it is to travel across it.
    A stronger link will be favored over weaker links in the computation of the shortest path between two words.}
    }

    \item \textbf{Clustering coefficient}, which measures the extent to which a node belongs to a local aggregate of tightly connected nodes~\citep{watts_collective_1998}, computed on the undirected \newtext{weighted} version of the FA network.\footnote{The Clustering coefficient is formally defined as the ratio between the number of actual versus possible edges between a node's neighbors;
    \newtext{this is poorly defined in the case of directed networks, which led us to ignore the direction of links in the network for this measure (if two words are connected in both directions, the weights of both links are added to make the final undirected link's weight).}
    }
    This tells us if a word belongs more or less to a local aggregate of equivalent words (from a free association point of view).

\end{APAitemize}

\subsubsection{Variable correlations}

\newtext{Several of these features are strongly related and can be grouped together.
To make correlation values as well as future comparisons more reliable, we log-transformed features that have marked exponential distributions (a few words valued orders of magnitude higher than the vast majority of other words).\footnote{
\newtext{The distributions of original and log-transformed features appears in the supplementary material, along with scatter plots for each feature pair, summarized below with correlation values.
}}}

\begin{figure}[!th]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/all-feature_correlations.png}
    \caption{Spearman correlations in the initial set of features}
    \label{fig:feature-corrs-initial}
\end{figure}

\begin{new}

The pairwise correlations in the initial set of features appears in Fig.~\ref{fig:feature-corrs-initial}.
By looking at absolute values, three subsets of highly correlated features can be easily identified:
(a) number of letters, phonemes, and syllables with pairwise correlations greater than .75;
(b) orthographic and phonological neighborhood densities, with a correlation of .8;
(c) age of acquisition, betweenness, degree, and pagerank centralities, with absolute pairwise correlations at .41, .6, .59, .63, .61 and .85.
Applying a feature agglomeration algorithm targeted at 6 groups refined this observation by producing identical (a) and (b) groups, a (c) group without betweenness centrality which was instead assigned to a group (d) with clustering coefficient, and the remaining features (frequency and number of synonyms) as singletons.\footnote{
\newtext{Agglomerating into less than 6 groups merged groups (a) and (b), which we excluded to keep neighborhood densities in their own group;
agglomerating into more than 6 groups separated age of acquisition from group (c), which we excluded given its high correlation values to the rest of group (c). 
We used scikit-learn's FeatureAgglomeration class for this procedure~\citep{pedregosa_scikit-learn:_2011}.}
}

Since our data is about written transformations, number of letters and orthographic neighborhood density are the natural representatives of groups (a) and (b) respectively.
Given the importance of age of acquisition in the lexical feature literature, we chose it to represent group (c).
Finally we used clustering coefficient to represent group (d) since it has already been used in previous studies.
The final set of features we will discuss in the rest of the paper, as well as their cross-correlations, can be seen in Fig.~\ref{fig:feature-corrs-filtered} (the analysis on the complete set of features can be found in the appendix).\footnote{
Note that feature values stem from different data sets which do not always encode the same words.
Indeed, we have data on frequency for about \newtext{33.5k} words, on age of acquisition for 30.1k words, on clustering coefficient for 5.7k words, number of synonyms 111.2k, and \newtext{orthographic density 17.8k words}.
Quite often then, not all features are available for all words in our data set;
however this is not problematic since the analysis is done on a per-feature basis, and not all words need be encoded in all features.}

\end{new}

\begin{figure}[!th]
    \centering
    \includegraphics[width=0.6412\linewidth]{images/computed-figures/paper-feature_correlations-v2.png}
    \caption{Spearman correlations in the filtered set of features}
    \label{fig:feature-corrs-filtered}
\end{figure}


\subsection{Substitution model}
\label{sec:temporal-binning}\label{sec:model}

We finally need a substitution detection model, for the \newtext{quotation} data we use presents a challenge:
quote-to-quote transformations and substitutions are not explicitly encoded in the data set.
More precisely, each set of quotations bears no explicit information about either the authoritative original quotation, or the source quotation(s) each author relied on when creating a new post and reproducing (and possibly altering) that source.
\newtext{In other words} we face an inference problem where, given all quotations and their occurrence timestamps, we must estimate which was the originating quotation for each instance of each quotation.

We therefore model the underlying quotation selection process by making a few additional assumptions.
\newtext{Given a particular occurrence of a quotation, the first issue is deciding whether} that occurrence is a strict copy of an earlier occurrence, or a substitution of another \newtext{quotation}, or maybe a substitution or copy from quotes appearing outside the data set, that is from a source external to the data collection perimeter.
\newtext{The second issue is deciding which source originated such a substitution when several candidate sources are available.}

Let us give an example:
\newtext{say the quotation "These accusations are false and \textbf{absurd}" ($q$) appears in two different blogs on January 19, and the slightly different quotation "These accusations are false and \textbf{incoherent}" ($q'$) appears in another blog on the 20th of January.
The second occurrence of $q$ can safely be assumed to be a faithful copy of the first one the same day.
And since $q$ is fairly prominent when $q'$ first appears, we could assume that the author of $q'$ on the 20th based herself on $q$ as is shown with a dashed line in Fig.~\ref{fig:substitution-unmodelled}.
Now say a third version, "These \textbf{allegations} are false and \textbf{incoherent}" ($q''$) also appears once on January 19 and once on January 20 after $q'$.
$q$ and $q''$ differ by two substitutions, so we discard the possibility that one was written based on the other (this below for further details).
$q''$ is only one substitution away from $q'$ however, so we could also consider the first occurrence of $q''$ as a potential source for $q'$ on the 20th.
Conversely, the occurrence of $q''$ on the 20th could be considered as a substitution from $q'$, or as a faithful copy from its initial occurrence on January 19.}
(Options shown in Fig.~\ref{fig:substitution-unmodelled}.)

\begin{figure}[h]
    \centering
	\def\svgwidth{\linewidth}
	\small
	\input{images/substitution-unmodelled.pdf_tex}
	\caption{{\bf Possible paths from occurrence to occurrence.}
	\newtext{$q$, $q'$ and $q''$ are three quotation variants belonging to the same cluster.
	$q$ and $q''$ differ by two words, but $q'$ differs from both $q$ and $q''$ by a word.
	The second occurrence of $q$ can safely be considered a faithful copy of the first, but the occurrences of $q'$ and $q''$ are uncertain:
	while the first occurrence of $q'$ is most likely a substitution from $q'$, it could also stem from $q''$;
	conversely, the second occurrence of $q''$ could also be a substitution from $q'$ instead of being a faithful copy of its first occurrence.}
	}
	\label{fig:substitution-unmodelled}
\end{figure}

\newtext{One way to settle these questions is the following:}
group quote occurrences into fixed bins spanning $\Delta t$ days (1 day in the implementation), each one representing a unit of time evolution;
when a quotation $q'$ appears in bin $t+1$, it is counted as a substitution if it differs from the most frequent quote of the preceding bin $t$ (or a substring thereof) by only one word;
if not, $q'$ is not considered to be an instance of substitution.
\newtext{Fig.~\ref{fig:substitution-modelled-majority-all} shows the inferences made by such a model.
The assumptions it embeds, however, are a subset of a much wider set of possibilities, each leading to alternative inferences.}

\begin{new}

We identified four binary parameters that differentiate potential models, such that the resulting 16 combinations cover most of the reasonable answers to inference uncertainties.
The first two parameters define the preceding time bin from which authors could have drawn a source when producing a new occurrence:
(1) \textbf{bin positions}, which can be discretized (aligning the end of a bin to midnight, as in the model presented above) or kept continuous (for each occurrence, use a bin that ends precisely at that occurrence);
(2) \textbf{bin span}, which can be 24 hours (as in the model above) or can be extended to start at the very first occurrence in the quotation family.
The other two parameters define rules on the selection of source and destination quotes of a substitution:
(3) \textbf{candidate sources} can be restricted to the most frequent quotations in the preceding time bin (as in the model above), or not (in which case all quotations in the preceding bin are candidate sources);
(4) \textbf{candidate destinations} can be restricted to quotations that do not appear in the preceding bin, or not (as in the model above).
A substitution model, then, is the given of a value for each of those parameters;
it considers valid all the substitutions (and only those) where the source and destination follow the rules set out by the parameters.
If a destination has substitutions from multiple sources we count a single effective substitution where, for each feature, the value for the effective source word is the average of the values of the candidate source words.

\end{new}
\begin{figure*}[h]
	\centering
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=majority-Past=last_bin-Durl=all.pdf_tex}
	    \caption{Source must be majority in preceding bin, destination can be anything}
	    \label{fig:substitution-modelled-majority-all}
	\end{subfigure}
	~
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=majority-Past=last_bin-Durl=exclude_past.pdf_tex}
	    \caption{Source must be majority in preceding bin, destination must not appear in preceding bin}
	    \label{fig:substitution-modelled-majority-exclude_past}
	\end{subfigure}

	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=all-Past=last_bin-Durl=all.pdf_tex}
	    \caption{Source can be anything, destination can be anything}
	    \label{fig:substitution-modelled-all-all}
	\end{subfigure}
	~
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=all-Past=last_bin-Durl=exclude_past.pdf_tex}
	    \caption{Source can be anything, destination must not appear in preceding bin}
	    \label{fig:substitution-modelled-all-exclude_past}
	\end{subfigure}
	\caption{\newtext{
	{\bf Substitution models.}
	Substitutions inferred by four models in the situation introduced by Fig.~\ref{fig:substitution-unmodelled}.
	Each of these models uses discretely positioned bins spanning 1 day (see the main text for a complete description of parameters).
	In the top left panel~(a), $q$ holds the majority in the first bin and is considered the unique basis for $q'$ in bin~2.
	$q'$ and $q''$ have equal maximum frequency in bin~2 however, so both are sources of substitutions towards bin~3.
	In the top right panel~(b), quotes that appear in the preceding bin cannot be the target of a substitution; this removes two substitutions compared to panel~(a).
	In the bottom left panel~(c), the majority constraint is lifted compared to panel~(a), making $q''$ in bin~1 a candidate source for $q'$ in bin~2.
	In the bottom right panel~(d), the majority constraint is also lifted compared to panel~(a) (adding the same $q'' \rightarrow q'$ substitution as in panel~(c)), and the excluded-past constraint is added as in panel~(b) (removing two same substitutions from bin~2 to bin~3 as in panel~(b)).
	If the bins were extended to the beginning of the quotation family, the excluded-past constraint would also remove the $q' \rightarrow q$ substitution from bin~2 to bin~3.
	In all four panels, a background rectangle or square indicates the quotation is the source of a substitution.
	A thick border on that rectangle or square indicates the quotation was selected because it has maximum frequency.}
	}
    \label{fig:substitution-modelled}
\end{figure*}

\begin{new}

Put shortly a model defines how many times, and under what source and destination conditions, quote occurrences can be counted as substitutions.
Fig.~\ref{fig:substitution-modelled} shows the inferences made by the four models that use discretely positioned bins spanning 1 day:
later occurrences of $q'$ and $q''$ are counted as substitutions in Fig.~\ref{fig:substitution-modelled-majority-all} and Fig.~\ref{fig:substitution-modelled-all-all}, whereas in Fig.~\ref{fig:substitution-modelled-majority-exclude_past} and Fig.~\ref{fig:substitution-modelled-all-exclude_past} they are not.

The results reported and discussed in the following sections are valid for all 16 models, and the graphics we present were produced by the model first introduced above.
Finally, note that this inference procedure is one of the reasons we restricted our analysis to single-substitutions:
looking for more complex transformations would
(a) exponentially increase the number of candidate sources for a destination occurrence, which correspondingly reduces the confidence in inferences made,
and (b) greatly increase the complexity of the transformation models used to make these inferences.\footnote{
\newtext{We checked that this restriction does not bias the results discussed below by extending our protocol to two-substitution transformations.
The results and graphics for the 16 additional models involved are available in the code repository for this paper: \url{https://github.com/wehlutyk/brainscopypaste}.}
}

\end{new}

\medskip

In practice \newtext{for the model first introduced above}, from the \newtext{2.60m} initial occurrences spread into 50,427 quotation families, with significant redundancy (many quotes are indeed simple duplicates), we mine \newtext{40,868} substitutions.
From these substitutions we remove those featuring stop words, minor spelling changes (e.g. center/centre, November/Nov, Senator/Sen), abbreviations, spelled out numbers, \newtext{words unknown to WordNet, and deletions in substrings (which can appear as substitutions of non-deleted words)};
this eventually yields \newtext{6,318} valid substitutions \newtext{(before merging substitutions that share the same destination)}.\footnote{
\newtext{Manually coding a random subset of 100 substitutions to evaluate this last filter showed that 84 were true negatives, 5 were false positives, and 11 true positives, giving a recall score of .688.
Precision was evaluated over a random subset of 100 \emph{kept} substitutions, showing a score of .87.
Finally, note that excluding minor spelling changes does not bias our use of orthographic neighborhood density as a feature:
out of the first 100 substitutions coded for recall, those with levenshtein distance equal to 1 (which is what orthographic neighborhood density codes,~\citealp{marian_clearpond:_2012}) were all typos or UK/US spelling changes, neither of which are relevant for this study.}
}

\section{Results}\label{sec:results}

\todo{Quick description of what types of substitutions we see (\#16)}

\todo{Mention distance in substitution}

We may now use this substitution model to formulate a family of psycholinguistic hypotheses describing the role of each feature in the accuracy of the reformulation.  To this end, we build two main observables for each word feature.
First, we measure the susceptibility for words to be the target of a substitution in a quote, knowing that there has been a variation, in order to show which semantic features are the most likely to ``attract'' a substitution under this condition. Second, we measure the change in word feature upon substitution, looking at the variation of a given feature between start and arrival words.

Note that since we only consider substitutions and not faithful copies, we measure the features of an alteration \emph{knowing that there has been an alteration}, and we do not take invariant quotations into account.
Indeed, in the former case we know there has been a human reformulation, whereas in the latter case it is impossible to know whether there has been perfect human reformulation or simply digital copy-pasting of a source~(``{\sc Ctrl-C}/{\sc Ctrl-V}'').
Furthermore, perfect human reformulation possibly involves different practices than those involved in alteration ---~for instance drafting before publishing, double-checking sources, proof-reading~--- and may not be representative of the cognitive processes at work during alteration.
The two situations are different enough to be studied separately, and we focus here on the latter.

\subsection{Susceptibility}

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/all-susceptibilities-pos.png}
    \caption{}
    \label{fig:pos-susceptibilities}
\end{figure}

We say that a word is \emph{substitutable} if it appears in a quote which undergoes a substitution, whether that substitution operates on that word or on another one.
Word substitution susceptibility is computed as the ratio of the number of times $s_w$ a word is substituted to the number of times $p_w$ that word appears in a substitutable position, that is $\sfrac{s_w}{p_w}$. {In other words, it measures how often a word $w$ actually gets substituted, compared to how often it could have been substituted (because it appears in quotes undergoing substitution)}.

Now, for a given feature $\phi$, we obtain the mean susceptibility $\sigma_{\phi}(f)$ for the feature value $f$ by averaging this ratio over all words such that $\phi(w) = f$, that is:

$$\sigma_{\phi}(f) = \left< \frac{s_w}{p_w} \right>_{\left\lbrace w | \phi(w) = f \right\rbrace}$$

Put shortly, susceptibility focuses on the selection of start words involved in substitutions, measuring the effect of features at the moment preceding the substitution when it is not yet known which word in the quotation will be substituted.

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-susceptibilities-quantilebins_global.png}
    \caption{\textbf{Substitution susceptibility:}% average susceptibility to substitution versus average feature value of a candidate word for substitution, with 95\% asymptotic confidence intervals.
    %The heatmap on the lower-right shows the joint effect of Number of synonyms and Number of phonemes on susceptibility, averaged over the respective single-variable ranges, with sample size (word numbers) in parentheses.
    }
    \label{fig:feature-susceptibilities-global}
\end{figure*}

\medskip

\todo{Exemplify with POS (note stopwords excluded) (\#16)}

\todo{Discuss results for global value, then (\#15) relate to missed literature}

Results for this measure are gathered in Fig.~\ref{fig:feature-susceptibilities}. They first show an obvious strong effect of Word frequency: the more frequent a word, the less likely it is to attract substitutions.
Indeed, susceptibility goes from $.33$ for low-frequency words down to nearly~0 for very high-frequency words.
To make things clear, this value of $.33$ means that low-frequency words, when present in a quote undergoing a substitution, are the ones being substituted 33\% of the time on average.

The other features --- Age of acquisition, Number of phonemes, Clustering coefficient and Number of synonyms --- do not seem to exhibit any particularly significant effect on susceptibility.
{If we set aside the values for low Number of phonemes}, for each of these features it is indeed possible to draw a constant line which always remains within the respective confidence intervals.
If these variables have an effect, it is by no means as strong as it is for Word frequency.
This is remarkably clear for Clustering coefficient and Age of acquisition, where susceptibility values remain within quite small intervals (respectively $[.13-.18]$ and $[.16-.20]$).
{We may notice a slight effect for the lowest values of Number of synonyms and Number of phonemes, where the mean susceptibility is almost half as high as the average of the other values (respectively $.09$ vs. $.16$, and $.11$ vs. $.17$).}
Keeping in mind the poor statistical significance of this effect, we could still wonder if the shortest words and words with fewest synonyms are significantly less susceptible to substitution.
To further examine this phenomenon, we plotted the two-dimensional map of susceptibility values for these two features (see heatmap at the bottom right of Fig.~\ref{fig:feature-susceptibilities}).
{Even if there are a few outlier cells, values tend to navigate around the mean value ($.16$) with little obvious regularity (except for a low number of synonyms, consistent with the unidimensional graph)}. {On the whole, this makes it relatively hard to draw any conclusion as regards the direction of an effect, except for the least populated value ranges (which as a result are also less significant).}

All in all, apart from Word frequency and despite some local tendencies, {in general} these results do not allow us to conclude to a marked effect %or to no effect
of the selected psycholinguistic features on substitution susceptibility.
We may therefore globally assume that substitution targets are chosen in a more or less uniform way with respect to these features.

\subsection{Variation}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-variations-quantilebins_global.png}
    \caption{\textbf{Feature variation upon substitution:} %$\nu_\phi$, average feature value of the appearing word as a function of the feature value of the disappearing word in a substitution, with 95\% asymptotic confidence intervals.
    %The overall position of the curve with respect to the dashed line representing $\mathcal{H}_0$ (constant $\nu_{\phi}^0$) indicates the direction of the cognitive bias.
    %The intersection with $y = x$ marks the attractor value.
    %The fact that all curves have slopes smaller than 1 means that the substitution operation is contractile on average: each feature will converge towards its own specific asymptotic range.
    }
    \label{fig:feature-variations-global}
\end{figure*}

We can thus show how words are modified once we know they are substituted, that is how their features are modified by said substitution.
Considering a word~$\wstart$ substituted for~$\warrival$, we measure how the feature of~$\wstart$ varies when it is replaced with~$\warrival$, that is we look at~$\phi(\warrival)$ as a function of~$\phi(\wstart)$.
Averaging this value over all start words such that $\phi(w) = f$ yields the mean variation for that feature value~$f$, that is:\footnote{To avoid possible autocorrelation effects due to substitutions belonging to the same cluster (which are likely not statistically independent and may lead to overly optimistic confidence intervals), we first average substitutions over each cluster, by considering the average of arrival word features for a given start word.}
$$\nu_{\phi}(f) = \left<\phi(\warrival)\right>_{\left\lbrace \wstart\rightarrow\warrival | \phi(\wstart) = f \right\rbrace}$$

Of prime interest is the comparison of the value of $\nu_{\phi}(f)$ with respect to $f$, as it shows whether there is an attraction (or a repulsion) effect towards (respectively from) some values of each feature.
In other words, plotting the $y=x$ line, we can see if substitutions tend to converge towards some typical value of a word feature or not --- as is classically done in the study of dynamical systems.

\todo{Introduce both H0 and H00}

We also introduce a null hypothesis $\mathcal{H}_0$ to compare the actual variation of a word's feature to its expected variation, assuming the arrival word $\warrival$ was randomly chosen from the whole pool of words available in the data set for that feature.\footnote{For instance, when considering the feature ``Clustering coefficient'', the arrival word is randomly chosen among words present in the data set of FA norms.}
In this case, since $\phi(\warrival)$ becomes a constant value in the above averaging (by definition $\warrival$ does not depend on $\wstart$ anymore),  the baseline variation under $\mathcal{H}_0$ may be rewritten as:\footnote{We additionally considered an alternative null hypothesis, denoted $\mathcal{H}_{00}$, where the arrival word is randomly chosen \emph{among immediate synonyms of the start word}, that is an arrival word chosen among semantically plausible though still random words. In this case $\warrival_{00}$ does depend on $\wstart$. Our conclusions hold under this second null hypothesis, so for the sake of clarity we chose to keep the simpler~$\mathcal{H}_0$.}
$$\nu_{\phi}^0 (f) = \left<\phi\right>$$

This approach yields a fine-grained view of how word features evolve upon substitution, on average, with respect to
\begin{seriate}
\item the original feature (\hbox{vs.} $y=x$) and
\item a random arrival (\hbox{vs.} $\nu_{\phi}^0$).
\end{seriate}

\medskip

\todo{Update results, explaining binning and toning down contractility, and relate to missed literature}

Results are gathered in Fig.~\ref{fig:feature-variations}.
We can do a first striking observation: all graphs show the existence of a unique intersection of $\nu_{\phi}$ with $y=x$, while the slope of $\nu_{\phi}$ is smaller than 1, independently of the feature considered.
In other words, beyond individual variation patterns, the substitution process is contractile for all the features, and each of them therefore exhibits a unique attractor.
Second, the comparison with $\nu_{\phi}^0$ shows that there are two classes of attractors, depending on whether:
\begin{APAenumerate}
\item there is a triple intersection (of $y=x$, $\nu_{\phi}^0$ and $\nu_{\phi}$);
\item or $\nu_{\phi}$ always remains above or below $\nu_{\phi}^0$.
\end{APAenumerate}
The first class (Number of phonemes and Number of synonyms) are features for which the substitution process only brings words slightly closer to $\nu_{\phi}^0$, and no uniform bias can be observed.
%\TB{(furthermore, $\mathcal{H}_{00}$ stays inside the confidence intervals of $\nu_{\phi}$, confirming that these two features are irrelevant for the substitution process)}.
%\rk{Cam: On vire ou bien?}


On the other hand, the second class (comprising Word frequency, Age of acquisition, and Clustering coefficient) are features for which the substitution process has a clear bias, positive or negative, with respect to the purely random situation ($\mathcal{H}_0$).

Word frequency, with $\nu_{\phi}$ always significantly above $\nu_{\phi}^0$, exhibits a strong bias towards more frequent words. This, in turn, is consistent with the hypothesis that substitution is a recall process, since common words are favored over awkward ones, while it goes against the idea that it could be a familiarity process, where awkward terms would be favored.

Age of acquisition and Clustering coefficient, on the other hand, exhibit a clear negative bias for the substitution process. Both curves are significantly below their respective $\nu_{\phi}^0$ values, which is consistent with the literature on recall: words learned earlier and words with lower clustering coefficient are easier to produce than average~\citep{nelson2013activation,Zevin02}.
Clustering coefficient has the additional particularity that, on average, the destination word does not depend on the start word; that is on average, substitutions will always produce words with a clustering coefficient around $\exp(-2.4) \simeq .1$.

To make things concrete, here is an example substitution taking place in the data set.
At the end of January 2009, many media websites reported the following quote,

\begin{quote}
    ``The massive economic upheaval being experienced across the globe is sparing no one in the consumer electronics world.''
\end{quote}
and a smaller number of media websites, and blogs, reported the following,
\begin{quote}
    ``The massive economic upheaval being experienced across the \textbf{world} is sparing no one in the consumer electronics world.''
\end{quote}
The word \emph{globe} is acquired at an average of 6.5 years old, appears about 3.5k times in the data set, and has a Clustering coefficient of $.24$.
The word it was replaced with, \emph{world}, is acquired on average at 5.3 years old, appears about 146k times in the data set, and has a Clustering coefficient of $.05$. (Both words have four phonemes.)
Such a change, though minor in appearance, is a typical example of alteration along the lines shown by our results.

%globe (age 6.5, phonemes 4.0, freq 8.18, cc -1.42, susceptibility 1.0)
%world  [age 5.32, phonemes 4.0, freq 11.89, cc -2.95, susceptibility 0.272727272727]

\subsection{Sentence context}

\todo{Explain in-sentence susceptibility and sentence-relative variation, relating to global value results}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-susceptibilities-sentencequantiles.png}
    \caption{}
    \label{fig:feature-susceptibilities-in_sentence}
\end{figure*}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-variations-quantilebins_sentencerel.png}
    \caption{}
    \label{fig:feature-variations-sentencerel}
\end{figure*}

\medskip
We thus observe a clear convergence pattern for each feature, with two different classes corresponding to the psychological relevance of each feature for the substitution process.
Taken as a dynamical system where substitutions are repeatedly applied, Number of phonemes and Number of synonyms will simply converge towards their average value in the FA corpus (i.e. $\nu_{\phi}^0)$, while Word frequency, Age of acquisition and Clustering coefficient, consistent with the literature, will converge towards significantly biased values indicated by the intersection with $y = x$ (respectively, a frequency of $\exp(9.1) \simeq 9000$, an acquisition age slightly below 8, and a Clustering coefficient of $.1$).

