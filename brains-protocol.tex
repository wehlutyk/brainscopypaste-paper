% !TEX root = brainscopycut.tex
% ============================
\section{Methods} % =========
% ============================
\label{sec:protocol}

\todo{\#20: check text/flow/definitions for clarity against Gureckis' edited pdf}

\newtext{We rely on a text corpus made of quotations extracted from online blog posts, and focus on their evolution.}
\newtext{Indeed} quotations appeared to be a perfect candidate to propose a first measure of \newtext{automatic} cognitive bias in \newtext{cultural transmission}.
First, they are usually cleanly delimited by quotation marks which greatly facilitates their detection in text corpora.
Second, they stem from a unique original version, and are ideally traceable back to that version.
Third, and most importantly, their duplication should \emph{a priori} be highly faithful, apart from cases of cropping:
not only should transformations be of moderate magnitude, but when specific words are not perfectly duplicated, it is safe to assume that the variation is due to involuntary cognitive bias --- as writers may expect any casual reader to easily verify, and thus criticize, the fidelity to the original quotation.

We could therefore study the individual transformation process at work when authors alter quotations, by examining the modified words in each transformation.
\newtext{Since our approach is exploratory however, we do not know at the outset which precise effect of cognitive bias we are looking for.
Indeed the data we use does not come from a controlled experiment in the laboratory, designed to elicit a particular effect: they are recordings of real life interactions, with all the complexity and uncertainty of conditions this entails.
%In this study, therefore, we did not try to predict and explain in detail the cognitive processes responsible for transformations
%\todo{, as this would be akin to a drink from the firehose. \sf [Cam: supprimer? potentiellement un excès d'autoflagellation -- en fait on devrait pouvoir dire simplement: ``The prediction and detailed explanation of the cognitive processes responsible for transformations is outside of the scope of this study'', probablement après la fin de la phrase suivante (``of a larger complexity (the detailed prediction and deconstruction of the cognitive processes etc. outside the scope etc. further research)'' mais même là cette modestie pourrait plutôt être de mise dans la conclusion? ou bien il s'agit d'une critique directe d'un reviewer ?  Un peu pareil pour ``our approach is exploratory'' (que j'ai laissé au nom de l'ambiguïté d'exploratoire qui veut aussi bien dire ``premier brouillon'' que ``data mining'') et ``this first study'' (où j'ai enlevé le `first' car trop ``bon c'est à moitié fini mais on soumet quand même'' ;) ]}
Our goal, therefore, is to show that such effects exist and are measurable even if they are part of a larger complexity (the detailed prediction and deconstruction of the cognitive processes responsible for them being left to further research).
%\todo{That is, we aim to prove first a relatively weak hypothesis before trying stronger ones. [Cam: idem, je supprimerais celle-là]}
If this is confirmed, we will have successfully applied laboratory analyses to out-of-laboratory data, opening a path to explanations of actual (\hbox{vs.} simulated) cultural evolution with tools from cognitive science.
As explained in the previous section, this is the reason we chose to use measures that can aggregate over all the transformations in the data set.}
\todo{this last sentence is unclear or not useful}

To keep the analysis \newtext{tractable}, we focused on quotation transformations consisting in the \emph{substitution} of a word by another word (and only those cases) in order to unambiguously discuss single word replacements.
\newtext{This restriction also allows us to more reliably infer the information that is missing in our data set, as explained further down (see "Substitution model").}
To quantify those substitutions we decided to associate a number of features to each word, the variation of which we can statistically study.

The next subsections describe the data set and the measures we used to assess this cognitive bias.

\subsection{\emph{In vivo} utterances}

We used a quotation data set collected by \citet{leskovec_meme-tracking_2009}, large enough to lend itself to statistical analysis.
This data set consists of the daily crawling of news stories and blog posts from around a million online sources, with an approximate publication rate of 900k texts per day, over a nine-month period of time from August 2008 to April 2009 (\citealp{leskovec_memetracker:_2009}).\footnote{
The original article~\citep{leskovec_meme-tracking_2009} does not provide further details on the source selection methodology.
}
\newtext{The authors automatically extracted quotations} from this corpus.
Each quotation is a more or less faithful excerpt of an utterance (oral or written) by the quoted person; for instance:
\begin{quote}
The Bank of England said, "these operations are designed to address funding pressures over quarter-end."
\end{quote}

\newtext{Then, the authors gathered quotations in a graph and connected each pair that differed by no more than one word or that shared at least ten consecutive words (they tested this procedure with a number of different parameters, see~\citealp{leskovec_meme-tracking_2009}, for more details).}
We find for example the following variation of the above quote:
\begin{quote}
"these operations are \textbf{intended} to address funding pressures over quarter-end."
\end{quote}
\newtext{Next, they applied a community detection algorithm} to that quotation graph to detect aggregates of tightly connected, that is sufficiently similar, groups of quotations~\citep[see again][for more details]{leskovec_meme-tracking_2009}.
This analysis yielded the final data we had access to, with a total of about \num{70000} sets of quotations; each of these sets ideally contains all variations of a same parent utterance, along with their respective publication URLs and timestamps \newtext{(since the procedure cannot be perfect, sets of quotations contain occasional rogue unrelated variations that should have been discarded or assigned to another set)}.

Manual inspection of this data set revealed that it contains a significant number of everyday language quotations (such as ``it was much better than I expected'', ``did that just happen'', as well as many simple expletive-based sentences).
Their presence is largely due to random variations around casual expressions, while we are interested in transformations of news-related quotes causally linked to an original, identifiable utterance.
To filter them out, we exclude quotes with less than 5 words or \newtext{whose occurrences span more} than 80 days (indicating causally unrelated occurrences), as well as quotes not written in English.
\newtext{Clusters that are emptied by this procedure are therefore excluded.}
If, after this screening, a cluster's occurrences still span more than 80 days (because of short-lived but unrelated quotes far apart in time), we also exclude it.
\newtext{We eventually keep 50,427 clusters (out of 71,568; \hbox{i.e.} 70.5\%), containing a total of 141,324 unique quotes (out of 310,457; \hbox{i.e.} 45.5\%) making up about 2.60m occurrences (out of 7.67m; \hbox{i.e.} 33.9\%).\footnote{
The significantly larger loss in occurrences indicates that, on average, the clusters we lose contain more occurrences than those we keep, which is to be expected for everyday language utterances.
}
Even if we lose some real event-related utterances which are present in clusters lasting more than 80 days (one such lost quote, for instance, is "the city is tired of me and the organization and I have run our course together"), we check that our approach fulfills its goals by coding a random sub-sample of 100 clusters:
35 of them are rejected by the filter, with 15 false negatives (rejected clusters that should have been kept) and 9 false positives (clusters kept when they should have been rejected), giving a precision score of 0.862 and a recall score of 0.789.
Furthermore, all but one of the 9 false positives are left with a single non-rejected quote, meaning those clusters are ignored by our substitution analysis; this brings the effective precision of our filter to 0.982.}\footnote{
\newtext{A similar analysis was made for language detection, which is part of the cluster filtering:
out of 100 randomly sampled quotes, 17 are rejected because their detected language is not English, with no false positives and 6 false negatives, giving a precision score of 1 and a recall score of 0.933.
Of the 6 false negatives, 4 had less than 5 tokens and would have been excluded by the cluster filter anyway.
}}


\subsection{Word-level measures}

\subsubsection{Lexical features}

We first introduce some lexical measures on words.

\begin{APAitemize}

    \item \textbf{Word frequency}: the frequency at which words appear in our data set, known to be relevant for both recognition and recall~\citep{gregg_word_1976},

    \item \textbf{Age of Acquisition}: the average age at which words are learned~\citep[obtained from][]{kuperman_age--acquisition_2012}, known to have different effects than word frequency~\citep{morrison_roles_1995,dewhurst_separate_1998},

    \item \newtext{\textbf{Phonological} and \textbf{Orthographic Neighborhood Density}~\citep[obtained from][]{marian_clearpond:_2012}, also known to be relevant for word production~\citep{garlock_age--acquisition_2001},}

    \item The average \textbf{Number of Phonemes} and \textbf{Number of Syllables} for all pronunciations of a word (obtained from the Carnegie Mellon University Pronouncing Dictionary, \citealp{weide_cmu_1998})\footnote{
    The CMU Pronouncing Dictionary is included in the NTLK package~\citep{bird_nltk_2009}, the natural language processing toolkit we used for the analysis.
    },
    \newtext{as well as \textbf{Number of Letters}}, as a proxy to word production cost,

    \item The average \textbf{Number of Synonyms} for all meanings of a word~\citep[obtained from][]{wordnet_princeton_2010} as an \emph{a priori} indicator of how easy it would be to replace a word.

\end{APAitemize}

\newtext{We also consider grammatical types within quotations by detecting \emph{Part-of-Speech} (POS) categories with TreeTagger~\citep{schmid_probabilistic_1994}; we distinguish between verbs, nouns, adjectives, adverbs, and stopword-like words.}

\medskip

\newtext{Aside from these raw features, the systemic dimension of vocabulary~\citep{cornish_systems_2013} has led authors to develop measures based on the full topology of networks built from free association data or phonological similarity.
Several such measures have been shown to be involved in recall, recognition, and naming tasks~\citep{nelson_how_2013,chan_network_2010,griffiths_google_2007}.}

\newtext{To compute those features} we relied on the free association (FA) norms collected by \citet{nelson_university_2004}, which record the words that come to mind when someone is presented with a given cue.
As \citet{nelson_university_2004} explain, "free association response probabilities index the likelihood that one word can cue another word to come to mind with minimal contextual constraints in effect."
\newtext{Similar to what \citet{griffiths_google_2007} did, we first considered the directed \newtext{weighted} network formed by association norms, where nodes are words and edges are directed from cue to target word, with a weight equal to the association strength (that is the probability of that target word being produced when this particular cue is presented).
This network is of particular interest since it lets us define features that reflect the associations driving false memories in word lists~\citep{deese_prediction_1959}, a phenomenon which may be involved in the transformation of quotations.}

We used three standard measures on the FA network:

\begin{APAitemize}

    \item \textbf{\newtext{Incoming} degree centrality}, measured by the number of cues for which a given word is triggered as a target, and a corresponding generalized measure, node \textbf{Pagerank}~\citep{page_pagerank_1999}, which has already been used on the FA network by \citet{griffiths_google_2007}.
    In the present case these two polysemy-related measures are quasi-perfectly correlated.\footnote{
    \newtext{Note that in-degree does not take the weights of links into account, as it counts 1 for each incoming link.
    Pagerank on the other hand, does take the weights into account.}
    }
    %, and measure polysemy by taking into account the structure of the entire network.
    %However in the present case there is a quasi-perfect correlation between node incoming degree and node \emph{pagerank}~\citep{Page99}, which will lead us to favour the latter later on. Word pagerank on the FA network had already been used by~\citet{Griffiths07}; it may be interpreted as a generalized and recursive measure of word polysemy: central nodes in the pagerank sense are words often selected as targets when presented with cues themselves often selected as targets, and so on recursively.

    \item \textbf{Betweenness centrality}, another measure of node centrality describing the extent to which a node connects otherwise remote areas of the network~\citep{freeman_set_1977}.
    This quantity tells us if some words behave as unavoidable waypoints on association chains connecting one word to another.\footnote{
    \newtext{For this measure, weights are interpreted as inverse cost:
    the stronger a link, the easier it is to travel across it.
    A stronger link will be favored over weaker links in the computation of the shortest path between two words.}
    }

    \item \textbf{Clustering coefficient}, which measures the extent to which a node belongs to a local aggregate of tightly connected nodes~\citep{watts_collective_1998}, computed on the undirected \newtext{weighted} version of the FA network.\footnote{The Clustering coefficient is formally defined as the ratio between the number of actual versus possible edges between a node's neighbors;
    \newtext{this is poorly defined in the case of directed networks, which led us to ignore the direction of links in the network for this measure (if two words are connected in both directions, the weights of both links are added to make the final undirected link's weight).}
    }
    This tells us if a word belongs more or less to a local aggregate of equivalent words (from a free association point of view).

\end{APAitemize}

\subsubsection{Variable correlations}

\newtext{Several of these features are strongly related and can be grouped together.
To make correlation values as well as future comparisons more reliable, we log-transformed features that have marked exponential distributions (a few words valued orders of magnitude higher than the vast majority of other words).\footnote{
\newtext{The distributions of original and log-transformed features appears in the Supplementary Information, along with scatter plots for each feature pair, summarized below with correlation values.
}}}

\begin{figure}[!th]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/all-feature_correlations.png}
    \caption{Spearman correlations in the initial set of features}
    \label{fig:feature-corrs-initial}
\end{figure}

\begin{new}

The pairwise correlations in the initial set of features appears in Fig.~\ref{fig:feature-corrs-initial}.
By looking at absolute values, three subsets of highly correlated features can be easily identified:
(a) number of letters, phonemes, and syllables with pairwise correlations greater than .75;
(b) orthographic and phonological neighborhood densities, with a correlation of .8;
(c) age of acquisition, betweenness, degree, and pagerank centralities, with absolute pairwise correlations at .41, .6, .59, .63, .61 and .85.
Applying a feature agglomeration algorithm targeted at 6 groups refined this observation by producing identical (a) and (b) groups, a (c) group without betweenness centrality which was instead assigned to a group (d) with clustering coefficient, and the remaining features (frequency and number of synonyms) as singletons.\footnote{
\newtext{Agglomerating into less than 6 groups merged groups (a) and (b), which we excluded to keep neighborhood densities in their own group;
agglomerating into more than 6 groups separated age of acquisition from group (c), which we excluded given its high correlation values to the rest of group (c). 
We used scikit-learn's FeatureAgglomeration class for this procedure~\citep{pedregosa_scikit-learn:_2011}.}
}

Since our data is about written transformations, number of letters and orthographic neighborhood density are the natural representatives of groups (a) and (b) respectively.
Given the importance of age of acquisition in the lexical feature literature, we chose it to represent group (c).
Finally we used clustering coefficient to represent group (d) since it has already been used in previous studies.
The final set of features we will discuss in the rest of the paper, as well as their cross-correlations, can be seen in Fig.~\ref{fig:feature-corrs-filtered} (the analysis on the complete set of features can be found in the appendix).\footnote{
Note that feature values stem from different data sets which do not always encode the same words.
Indeed, we have data on frequency for about \newtext{33.5k} words, on age of acquisition for 30.1k words, on clustering coefficient for 5.7k words, number of synonyms 111.2k, and \newtext{orthographic density 17.8k words}.
Quite often then, not all features are available for all words in our data set;
however this is not problematic since the analysis is done on a per-feature basis, and not all words need be encoded in all features.}

\end{new}

\begin{figure}[!th]
    \centering
    \includegraphics[width=0.6412\linewidth]{images/computed-figures/paper-feature_correlations-v2.png}
    \caption{Spearman correlations in the filtered set of features}
    \label{fig:feature-corrs-filtered}
\end{figure}


\subsection{Substitution model}
\label{sec:temporal-binning}\label{sec:model}

We finally need a substitution detection model, for the \newtext{quotation} data we use presents a challenge:
quote-to-quote transformations and substitutions are not explicitly encoded in the data set.
More precisely, each set of quotations bears no explicit information about either the authoritative original quotation, or the source quotation(s) each author relied on when creating a new post and reproducing (and possibly altering) that source.
\newtext{In other words} we face an inference problem where, given all quotations and their occurrence timestamps, we must estimate which was the originating quotation for each instance of each quotation.

We therefore model the underlying quotation selection process by making a few additional assumptions.
\newtext{Given a particular occurrence of a quotation, the first issue is deciding whether} that occurrence is a strict copy of an earlier occurrence, or a substitution of another \newtext{quotation}, or maybe a substitution or copy from quotes appearing outside the data set, that is from a source external to the data collection perimeter.
\newtext{The second issue is deciding which source originated such a substitution when several candidate sources are available.}

Let us give an example:
\newtext{say the quotation "These accusations are false and \textbf{absurd}" ($q$) appears in two different blogs on January 19, and the slightly different quotation "These accusations are false and \textbf{incoherent}" ($q'$) appears in another blog on the 20th of January.
The second occurrence of $q$ can safely be assumed to be a faithful copy of the first one the same day.
And since $q$ is fairly prominent when $q'$ first appears, we could assume that the author of $q'$ on the 20th based herself on $q$ as is shown with a dashed line in Fig.~\ref{fig:substitution-unmodelled}.
Now say a third version, "These \textbf{allegations} are false and \textbf{incoherent}" ($q''$) also appears once on January 19 and once on January 20 after $q'$.
$q$ and $q''$ differ by two substitutions, so we discard the possibility that one was written based on the other (this below for further details).
$q''$ is only one substitution away from $q'$ however, so we could also consider the first occurrence of $q''$ as a potential source for $q'$ on the 20th.
Conversely, the occurrence of $q''$ on the 20th could be considered as a substitution from $q'$, or as a faithful copy from its initial occurrence on January 19.}
(Options shown in Fig.~\ref{fig:substitution-unmodelled}.)

\begin{figure}[h]
    \centering
	\def\svgwidth{\linewidth}
	\small
	\input{images/substitution-unmodelled.pdf_tex}
	\caption{{\bf Possible paths from occurrence to occurrence.}
	\newtext{$q$, $q'$ and $q''$ are three quotation variants belonging to the same cluster.
	$q$ and $q''$ differ by two words, but $q'$ differs from both $q$ and $q''$ by a word.
	The second occurrence of $q$ can safely be considered a faithful copy of the first, but the occurrences of $q'$ and $q''$ are uncertain:
	while the first occurrence of $q'$ is most likely a substitution from $q'$, it could also stem from $q''$;
	conversely, the second occurrence of $q''$ could also be a substitution from $q'$ instead of being a faithful copy of its first occurrence.}
	}
	\label{fig:substitution-unmodelled}
\end{figure}

\newtext{One way to settle these questions is the following:}
group quote occurrences into fixed bins spanning $\Delta t$ days (1 day in the implementation), each one representing a unit of time evolution;
when a quotation $q'$ appears in bin $t+1$, it is counted as a substitution if it differs from the most frequent quote of the preceding bin $t$ (or a substring thereof) by only one word;
if not, $q'$ is not considered to be an instance of substitution.
\newtext{Fig.~\ref{fig:substitution-modelled-majority-all} shows the inferences made by such a model.
The assumptions it embeds, however, are a subset of a much wider set of possibilities, each leading to alternative inferences.}

\begin{new}

We identified four binary parameters that differentiate potential models, such that the resulting 16 combinations cover most of the reasonable answers to inference uncertainties.
The first two parameters define the preceding time bin from which authors could have drawn a source when producing a new occurrence:
(1) \textbf{bin positions}, which can be aligned to midnight (as in the model presented above) or kept sliding (for each occurrence, use a bin that ends precisely at that occurrence);
(2) \textbf{bin span}, which can be 24 hours (as in the model above) or can be extended to start at the very first occurrence in the quotation family.
The other two parameters define rules on the selection of source and destination quotes of a substitution:
(3) \textbf{candidate sources} can be restricted to the most frequent quotations in the preceding time bin (as in the model above), or not (in which case all quotations in the preceding bin are candidate sources);
(4) \textbf{candidate destinations} can be restricted to quotations that do not appear in the preceding bin, or without restriction (as in the model above).
A substitution model, then, is the given of a value for each of those parameters;
it considers valid all the substitutions (and only those) where the source and destination follow the rules set out by the parameters.
If a destination has substitutions from multiple sources we count a single effective substitution where, for each feature, the value for the effective source word is the average of the values of the candidate source words.

\end{new}
\begin{figure*}[h]
	\centering
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=majority-Past=last_bin-Durl=all.pdf_tex}
	    \caption{Source must be majority in preceding bin, destination can be anything}
	    \label{fig:substitution-modelled-majority-all}
	\end{subfigure}
	~
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=majority-Past=last_bin-Durl=exclude_past.pdf_tex}
	    \caption{Source must be majority in preceding bin, destination must not appear in preceding bin}
	    \label{fig:substitution-modelled-majority-exclude_past}
	\end{subfigure}

	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=all-Past=last_bin-Durl=all.pdf_tex}
	    \caption{Source can be anything, destination can be anything\\\hfill} % \\\hfill to add a line, aligning with the other panels which have two-line captions
	    \label{fig:substitution-modelled-all-all}
	\end{subfigure}
	~
	\begin{subfigure}{.49\textwidth}
	    \def\svgwidth{\textwidth}
	    \small
	    \input{images/substitution-Time=discrete-Source=all-Past=last_bin-Durl=exclude_past.pdf_tex}
	    \caption{Source can be anything, destination must not appear in preceding bin}
	    \label{fig:substitution-modelled-all-exclude_past}
	\end{subfigure}
	\caption{\newtext{
	{\bf Substitution models.}
	Substitutions inferred by four models in the situation introduced by Fig.~\ref{fig:substitution-unmodelled}.
	Each of these models uses discretely positioned bins spanning 1 day (see the main text for a complete description of parameters).
	In the top left panel~(a), $q$ holds the majority in the first bin and is considered the unique basis for $q'$ in bin~2.
	$q'$ and $q''$ have equal maximum frequency in bin~2 however, so both are sources of substitutions towards bin~3.
	In the top right panel~(b), quotes that appear in the preceding bin cannot be the target of a substitution; this removes two substitutions compared to panel~(a).
	In the bottom left panel~(c), the majority constraint is lifted compared to panel~(a), making $q''$ in bin~1 a candidate source for $q'$ in bin~2.
	In the bottom right panel~(d), the majority constraint is also lifted compared to panel~(a) (adding the same $q'' \rightarrow q'$ substitution as in panel~(c)), and the excluded-past constraint is added as in panel~(b) (removing two same substitutions from bin~2 to bin~3 as in panel~(b)).
	If the bins were extended to the beginning of the quotation family, the excluded-past constraint would also remove the $q' \rightarrow q$ substitution from bin~2 to bin~3.
	In all four panels, a background rectangle or square indicates the quotation is the source of a substitution.
	A thick border on that rectangle or square indicates the quotation was selected because it has maximum frequency.}
	}
    \label{fig:substitution-modelled}
\end{figure*}

\begin{new}

Put shortly a model defines how many times, and under what source and destination conditions, quote occurrences can be counted as substitutions.
Fig.~\ref{fig:substitution-modelled} shows the inferences made by the four models that use discretely positioned bins spanning 1 day:
later occurrences of $q'$ and $q''$ are counted as substitutions in Fig.~\ref{fig:substitution-modelled-majority-all} and Fig.~\ref{fig:substitution-modelled-all-all}, whereas in Fig.~\ref{fig:substitution-modelled-majority-exclude_past} and Fig.~\ref{fig:substitution-modelled-all-exclude_past} they are not.

The results reported and discussed in the following sections are valid for all 16 models, and the graphics we present were produced by the model first introduced above.
Finally, note that this inference procedure is one of the reasons we restricted our analysis to single-substitutions:
looking for more complex transformations would
(a) exponentially increase the number of candidate sources for a destination occurrence, which correspondingly reduces the confidence in inferences made,
and (b) greatly increase the complexity of the transformation models used to make these inferences.\footnote{
\newtext{We checked that this restriction does not bias the results discussed below by extending our protocol to two-substitution transformations.
The results and graphics for the 16 additional models involved are available in the code repository for this paper: \url{https://github.com/wehlutyk/brainscopypaste}.}
}

\end{new}

\medskip

In practice \newtext{for the model first introduced above}, from the \newtext{2.60m} initial occurrences spread into 50,427 quotation families, with significant redundancy (many quotes are indeed simple duplicates), we mine \newtext{40,868} substitutions.
From these substitutions we remove those featuring stop words, minor spelling changes (e.g. center/centre, November/Nov, Senator/Sen), abbreviations, spelled out numbers, \newtext{words unknown to WordNet, and deletions in substrings (which can appear as substitutions of non-deleted words)};
this eventually yields \newtext{6,318} valid substitutions \newtext{(before merging substitutions that share the same destination)}.\footnote{
\newtext{Manually coding a random subset of 100 substitutions to evaluate this last filter showed that 84 were true negatives, 5 were false positives, and 11 true positives, giving a recall score of .688.
Precision was evaluated over a random subset of 100 \emph{kept} substitutions, showing a score of .87.
Finally, note that excluding minor spelling changes does not bias our use of orthographic neighborhood density as a feature:
out of the first 100 substitutions coded for recall, those with levenshtein distance equal to 1 (which is what orthographic neighborhood density codes,~\citealp{marian_clearpond:_2012}) were all typos or UK/US spelling changes, neither of which are relevant for this study.}
}

\section{Results}\label{sec:results}

\begin{new}

While most of the substitutions we obtain with this procedure replace a word with another semantically related word, the two are rarely direct synonyms:
only a third of all substitutions travel less than 3 hops on the hyponym-hypernym network defined by WordNet (direct synonyms count as 0~hops on this network), meaning that at least two thirds involve non-synonyms.\footnote{
\newtext{A similar behavior is observed on the FA network, where about 104 clusters have substitutions traveling only 1 hop, 110 traveling 2 hops, 137 traveling 3, 72 traveling 4, and 13 traveling 5.
}}
Compared to the word it replaces, the new word usually achieves a similar meaning in the context of its sentence while still slightly changing the implications or the attitude expressed by the author.
The following examples illustrate this behavior:

\begin{APAitemize}
	\item ``This is \{socialism~$\rightarrow$~welfare\} for the rich'',
	\item {[}The{]} ``perverse logic of \{clashes~$\rightarrow$~confrontation\} and violence'',
	\item ``This \{crisis~$\rightarrow$~problem\} did not develop overnight and it will not be solved overnight''.
\end{APAitemize}

\end{new}

\newtext{Our question concerns the low-level properties of these substitutions; to address it} we build the following two observables for each word feature.
First, we measure \newtext{which word features are more or less substituted compared to how often they would be if the process were random, in order to capture} the susceptibility for words to be the target of a substitution in a quote.
Second, we measure the change in word feature upon substitution, looking at the variation of a given feature between start and arrival words.
\newtext{Since sentence context is also central to this process, we extend these two observables by applying them to feature values relative to the distribution of feature values of the sentence in which a word appears.}

Note that since we only consider substitutions and not faithful copies, we measure the features of an alteration \emph{knowing that there has been an alteration}, \newtext{that is} we do not take invariant quotations into account.
Indeed, in the former case we know there has been a human reformulation, whereas in the latter case it \newtext{we cannot} know whether there has been perfect human reformulation or simply digital copy-pasting of a source~(``{\sc Ctrl-C}/{\sc Ctrl-V}'').
\newtext{Moreover}, perfect human reformulation possibly involves different practices than those involved in alteration ---~for instance drafting before publishing, double-checking sources, proof-reading~--- and may not be representative of the cognitive processes at work during alteration.
The two situations are different enough to be studied separately, and we focus here on the latter.

\subsection{Susceptibility}

We say that a word is \emph{substitutable} if it appears in a quote which undergoes a substitution, whether the substitution operates on that word or on another one.
% utiliser "word-level measures", et/ou "For a given value of a given type of word-level measure (say, words of length 5), we define susceptibility as the ratio (...)"
\newtext{For a given group of words $g$ \todo{[not clear this is not a given word -- maybe present by example instead of generally]}, susceptibility is computed as the ratio of the number of times $s_g$ words of that group are substituted to the number of times $s_g^0$ words of that group would be substituted if substitutions fell randomly on substitutable words, that is:}\footnote{
\newtext{$s_g^0$ is computed by summing, over all quotes undergoing a substitution, the ratio of the number of words in a quote that are from group $g$ to the number of words in the same quote that could have been the substitution's target.
If, for instance, half the content words of a given quote are from group $g$, such a quote contributes .5 to the total $s_g^0$.}
}
$$\sigma_g = \frac{s_g}{s_g^0}$$

In other words, susceptibility measures \newtext{how much more or less a group of words $g$ actually gets substituted compared to picking targets at random in quotes undergoing substitutions}.
\newtext{By applying this measure to Part-of-Speech (POS) categories and feature bins (e.g. for a feature $\phi$ and a bin $[a, b]$, $g = \{w | \phi(w) \in [a, b]\}$), susceptibility measures the bias in} the selection of start words involved in substitutions, \newtext{that is} the effect of word \newtext{properties} at the moment preceding the substitution when it is not yet known which word in the quotation will be substituted.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/all-susceptibilities-pos.png}
    \caption{\newtext{\textbf{Substitution susceptibility for POS categories:} categories are simplified from the TreeTagger tag set: \emph{J} means adjective, \emph{N}~noun, \emph{R}~adverb, \emph{V}~verb, and \emph{Stopword-like} gathers together all the categories partially or completely affected by the stopword filter (see main text for details).
    The top panel shows the actual $s_{POS}$ and $s_{POS}^0$ counts, the bottom panel shows $\sigma_{POS}$, the ratio of the two.
    Confidence intervals are computed with the Goodman method for multinomial proportions.}
    \todo{Split into 2 subfigures; fix labels; use log-y for second pane; add H0 dashed line.}}
    \label{fig:pos-susceptibilities}
\end{figure}



\medskip

\begin{new}

Fig.~\ref{fig:pos-susceptibilities} gathers the results for POS groups.
A Goodman-based multinomial goodness-of-fit test~\citep{goodman_simultaneous_1965} shows that these categories have a significant effect on susceptibility ($p < .05$ in all substitution models), but this seems mostly due to the \emph{Stopword-like}\footnote{
\newtext{The \emph{Stopword-like} category gathers all the POS groups partially of completely affected by the stopword filter for substitutions: coordinating conjunctions, foreign words, prepositions, subordinating conjunctions, modals, possessive endings, punctuation symbols and interjections.
Note that the stopword filter equally affects $s$ and $s^0$, so while both numbers are very small for these categories (which led us to group them together) the reported susceptibility is not biased by this filtering.}
}
and \emph{Adverb} categories.
Indeed, detailing which categories are out of their confidence region under $\mathcal{H}_0$ shows that susceptibility for stopword-likes is significantly below 1 (confirmed in all substitution models), as is that for adverbs in 13 of the 16 substitution models;
none of the other categories are significantly different from $\mathcal{H}_0$ (except nouns which appear significantly above 1 in a single substitution model).
While we acknowledge the low susceptibilities of adverbs and stopword-likes, these categories concern less than 7\% of all substitutions under $\mathcal{H}_0$ (and even less in the actual data);
it seems, then, that POS categories don't capture any strong bias in the selection of substitution targets.

\end{new}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-susceptibilities-quantilebins_global.png}
    \caption{\textbf{Substitution susceptibility for feature values:} susceptibility to substitution versus feature value of a candidate word for substitution \newtext{(binned by quartiles)}, with 95\% asymptotic confidence intervals \newtext{(Goodman-based multinomial)}.
    \todo{Use log-y}
    }
    \label{fig:feature-susceptibilities-global}
\end{figure*}

\todo{Relate to missed literature (\#15)}

\begin{new}

The results for word features presented in Fig.~\ref{fig:feature-susceptibilities-global}, on the other hand, show marked effects for several features.
Word frequency, Age of acquisition, and Number of letters each exhibit significant susceptibility variations (Goodman goodness-of-fit with $p < .05$ in all substitution models, $p < .001$ in most) consistent with known effects of those features on recall.
High-frequency words, much easier to recall, are substituted about half as much as they would be at random; conversely low-frequency words, harder to recall, are substituted about 50\% more than random.
Age of acquisition and Number of letters show the opposite pattern, consistent with their negative correlation to word frequency ($-.4$ and $-.19$):
words learned before 5 or 6 years old, or made of less than 5 letters, are substituted less than random, whereas words learned after 10 years old, or made of more than 8 letters, are substituted far more than random.
Orthographic neighborhood density also shows a slight effect (significant at $p < .05$ in 15 of the 16 substitution models):
words with very sparse neighborhoods are more substituted than random (which may seem counter-intuitive, but is likely because over 70\% of those words have 7 letters or more).
Clustering coefficient shows no effect on susceptibility, and neither does Number of synonyms:
in particular, words with many synonyms do not attract substitutions more than random (in fact, half the substitution models show they have a slight tendency to be substituted less than random).

On the whole, the trends observed are consistent with known effects of word frequency, age of acquisition, and number of letters, indicating that the triggering of a substitution could behave quite similarly to word recall in standard tasks.

\end{new}

\subsection{Variation}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-variations-quantilebins_global.png}
    \caption{\textbf{Feature variation upon substitution:} %$\nu_\phi$, average feature value of the appearing word as a function of the feature value of the disappearing word in a substitution, with 95\% asymptotic confidence intervals.
    %The overall position of the curve with respect to the dashed line representing $\mathcal{H}_0$ (constant $\nu_{\phi}^0$) indicates the direction of the cognitive bias.
    %The intersection with $y = x$ marks the attractor value.
    %The fact that all curves have slopes smaller than 1 means that the substitution operation is contractile on average: each feature will converge towards its own specific asymptotic range.
    }
    \label{fig:feature-variations-global}
\end{figure*}

We \newtext{now examine} how words are modified \newtext{when} they are substituted, that is how their features change upon substitution.
Considering a word~$\wstart$ substituted for~$\warrival$, we measure how a feature~\newtext{$\phi$} of~$\wstart$ varies when it is replaced with~$\warrival$, that is we look at~$\phi(\warrival)$ as a function of~$\phi(\wstart)$.
Averaging this value over all start words such that $\phi(w) = f$ yields the mean variation for that feature value~$f$, that is:\footnote{To avoid possible autocorrelation effects due to substitutions belonging to the same cluster (which are likely not statistically independent and may lead to overly optimistic confidence intervals), we first average substitutions over each cluster, by considering the average of arrival word features for a given start word. \todo{explain this for susceptibility too}}
$$\nu_{\phi}(f) = \left<\phi(\warrival)\right>_{\left\lbrace \wstart\rightarrow\warrival | \phi(\wstart) = f \right\rbrace}$$

\newtext{We are interested in comparing} the value of $\nu_{\phi}(f)$ to $f$ \newtext{itself}, as \newtext{this} shows whether there is an attraction (or a repulsion) effect towards (respectively from) some values of each feature.
In other words, plotting the $y=x$ line, we can see if substitutions tend to \newtext{attract words} towards some typical \newtext{feature value} or not --- \newtext{a standard procedure} in the study of dynamical systems.

We also introduce \newtext{two} null \newtext{hypotheses}, $\mathcal{H}_0$ \newtext{and $\mathcal{H}_{00}$}, to compare the actual variation of a word's feature to expected variations \newtext{under unbiased transformations}.
\newtext{$\mathcal{H}_0$ models the situation where} the arrival word $\warrival$ \newtext{is} randomly chosen from the whole pool of words available in the data set for that feature.\footnote{
For instance, when considering the feature ``Clustering coefficient'', the arrival word is randomly chosen among words present in the data set of FA norms.
}
In this case, since $\phi(\warrival)$ becomes a constant value in the above averaging (by definition $\warrival$ does not depend on $\wstart$ anymore), the baseline variation under $\mathcal{H}_0$ may be rewritten as:
$$\nu_{\phi}^0 (f) = \left<\phi\right>$$
\newtext{$\mathcal{H}_{00}$ models the situation where the arrival word $\warrival$ is chosen \emph{among immediate synonyms of the start word} $\wstart$, that is an arrival word chosen among semantically plausible though still random words.
In this case $\nu_{\phi}^{00}$ does depend on $f$:\footnote{
\newtext{The actual implementation has an additional level of averaging since WordNet, used to get a word's synonyms, defines several meanings for a single given word.
Therefore:
$$\nu_{\phi}^{00} (f) = \left< \left< \left< \phi(\warrival) \right>_{\warrival \in syn(m)} \right>_{m \in meanings(\wstart)} \right>_{\left\lbrace \wstart | \phi(\wstart) = f \right\rbrace}$$}
}
$$\nu_{\phi}^{00} (f) = \left< \left< \phi(\warrival) \right>_{\warrival \in syn(\wstart)} \right>_{\left\lbrace \wstart | \phi(\wstart) = f \right\rbrace}$$}

This approach yields a fine-grained view of how word features evolve upon substitution, on average, with respect to
\begin{seriate}
\item the original feature (\hbox{vs.} $y=x$),
\item a random arrival (\hbox{vs.} $\nu_{\phi}^0$), \newtext{and
\item an unbiased semantically plausible arrival (\hbox{vs.} $\nu_{\phi}^{00}$)}.
\end{seriate}

\medskip

\todo{Update results, explaining binning and toning down contractility, and relate to missed literature}

Results are gathered in Fig.~\ref{fig:feature-variations-global}.
A first observation is that all graphs show the existence of a unique intersection of $\nu_{\phi}$ with $y=x$, and the slope of $\nu_{\phi}$ is smaller than 1 in absolute value, independently of the feature considered.
\newtext{This means that for each feature $\phi$, whichever the value $\phi(\wstart)$ of the start word, the arrival word's feature value $\phi(\warrival)$ will, on average, be closer to that feature's intersection between $\nu_{\phi}$ and $y=x$.\footnote{
\newtext{The observation becomes obvious when one manually simulates a substitution on the graph by picking a start value, using the $\nu_{\phi}$ curve to obtain the corresponding arrival value, and comparing it to the start value:
it is always closer to the intersection with $y=x$, meaning that that intersection is an attractor point for the substitution process.
If the slope of $\nu_{\phi}$ were greater than one (in absolute value), the arrival value would always be \emph{farther} from the intersection than the start value was, making it a \emph{repulsor} point.
This is how the number of intersections with $y=x$, and the slope of $\nu_{\phi}$ at those intersections, characterize the behavior of substitutions.
}}}
In other words, beyond individual variation patterns, the substitution process exhibits a unique attractor \newtext{for each feature}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/paper-variations_regression-globals_to_globalsvariation.png}
    \caption{\newtext{\textbf{Coefficients of the regressions of feature variations:}
	\todo{only aoa and clustering are impacted by frequency, the rest is only impacted by itself}
	}}
    \label{fig:feature-variations_regression-global}
\end{figure}

Second, the comparison with $\nu_{\phi}^0$ \newtext{and $\nu_{\phi}^{00}$} shows that there are two classes of attractors, depending on whether:
\begin{APAenumerate}
\item there is a triple intersection (of $y=x$, $\nu_{\phi}$, \newtext{and $\nu_{\phi}^0$ or $\nu_{\phi}^{00}$});
\item or $\nu_{\phi}$ always remains above or below $\nu_{\phi}^0$ \newtext{and $\nu_{\phi}^{00}$}.
\end{APAenumerate}
The first class (Number of synonyms and \newtext{Orthographic neighborhood density}) are features for which the substitution process only brings words slightly closer to $\nu_{\phi}^0$ \newtext{(for Number of synonyms) or $\nu_{\phi}^{00}$ (for Orthographic neighborhood density)}, and no uniform bias can be observed.
The second class (comprising Word frequency, Age of acquisition, Clustering coefficient\newtext{, and Number of letters}) are features for which the substitution process has a clear bias, positive or negative, with respect to \newtext{both} the purely random situation ($\mathcal{H}_0$) \newtext{and the semantically plausible random situation ($\mathcal{H}_{00}$)}.

Word frequency, with $\nu_{\phi}$ always significantly above $\nu_{\phi}^0$ \newtext{and $\nu_{\phi}^{00}$}, exhibits a strong bias towards more frequent words.
This, in turn, is consistent with the hypothesis that substitution is a recall process, since common words are favored over awkward ones.%, while it goes against the idea that it could be a familiarity process, where awkward terms would be favored.
Age of acquisition, Clustering coefficient \newtext{and Number of letters}, on the other hand, exhibit a clear negative bias for the substitution process (except for high clustering values or very high number of letters).
\newtext{The three} curves are significantly below their respective $\nu_{\phi}^0$ \newtext{and $\nu_{\phi}^{00}$ curves for most start values}, which is consistent with the literature on recall:
words learned earlier, with lower clustering coefficient \newtext{or with fewer letters} are easier to produce than average~\citep{nelson_how_2013,zevin_age_2002,baddeley_word_1975}.

To make things concrete, here is an example substitution taking place in the data set.
\newtext{Around mid-November 2008, several media websites reported the following quote from Burmese poet Saw Wai (arrested for one of his poems),
\begin{quote}
    ``Senior general Than Shwe is foolish with power.''
\end{quote}
and a smaller number of media websites, and blogs, reported the following,
\begin{quote}
    ``Senior general Than Shwe is \textbf{crazy} with power.''
\end{quote}
The word \emph{foolish} is acquired at an average of 8.94 years old, appears 675 times in the data set, has a Clustering coefficient of $8.2 \times 10^{-3}$ and is 7 letters long.
The word it was replaced with, \emph{crazy}, is acquired on average at 5.22 years old, appears about 4.1k times in the data set, has a Clustering coefficient of $1.7 \times 10^{-3}$, and is 5 letters long.}
Such a change, though minor in appearance, is a typical example of alteration along the lines shown by our results.

% foolish / crazy
%  frequency: (6.5147126908725301, 8.3192299386323256)
%  aoa: (8.94, 5.22)
%  clustering: (-4.7983132551456364, -6.369204119494885)
%  letters_count: (7, 5)

\subsection{Sentence context}

\todo{Explain in-sentence susceptibility and sentence-relative variation, relating to global value results}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-susceptibilities-sentencequantiles.png}
    \caption{}
    \label{fig:feature-susceptibilities-in_sentence}
\end{figure*}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/paper-variations-quantilebins_sentencerel.png}
    \caption{\todo{Bring back to 1, and use log-y}}
    \label{fig:feature-variations-sentencerel}
\end{figure*}

\medskip
We thus observe a clear convergence pattern for each feature, with two different classes corresponding to the psychological relevance of each feature for the substitution process.
Taken as a dynamical system where substitutions are repeatedly applied, Number of phonemes and Number of synonyms will simply converge towards their average value in the FA corpus (i.e. $\nu_{\phi}^0)$, while Word frequency, Age of acquisition and Clustering coefficient, consistent with the literature, will converge towards significantly biased values indicated by the intersection with $y = x$ (respectively, a frequency of $\exp(9.1) \simeq 9000$, an acquisition age slightly below 8, and a Clustering coefficient of $.1$).

