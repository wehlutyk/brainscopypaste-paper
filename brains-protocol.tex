% !TEX root = brainscopycut.tex
% ============================
\section{Methods} % =========
% ============================
\label{sec:protocol}

%In order to start bridging this gap, we set out to \emph{empirically} study public representation transformations at the microscopic level; 
%aiming to stay compatible with macroscopic-level studies of these public representations.
Quotations appeared to be a perfect candidate to propose a first \emph{in vivo} measure of low-level cognitive bias in a reformulation task. % as public representations.
First, they are usually cleanly delimited by quotation marks %(and often with HTML markup in web pages), 
which greatly facilitates their detection in text corpora.
Second, they stem from a unique ``original'' version, and could ideally be traceable back to that version.
Third, and most importantly, their duplication should \emph{a priori} be highly faithful, apart from cases of cropping: not only should transformations be of moderate magnitude, but when specific words are not perfectly duplicated, it is safe to assume that the variation is due to involuntary cognitive bias --- as writers may expect any casual reader to easily verify, and thus criticize, the fidelity to the original quotation.


We could therefore examine the individual substitution process at work when authors transform quotations, by examining the features of the substituted and substituting words in each substitution. To keep the analysis palatable, we focused on quotation transformations consisting in the \emph{substitution} of a word by another word (and only those cases) in order to unambiguously discuss single word replacements. 
To quantify those substitutions, we decided to associate a number of features to each word, the variation of which we can statistically study.

The next subsections describe the dataset and measures we used to assess this cognitive bias.
%Quotation evolution is therefore a perfect environment to measure cognition-induced transformations.%and relate those findings to macroscopic social dynamics.

\subsection{In vivo utterances}

We used a quotation dataset collected by \citet{Leskovec09}, large enough to lend itself to statistical analysis.
This dataset consists of the daily crawling of news stories and blog posts from around a million online sources, with an approximate publication rate of 900k texts per day, over a nine-month period of time (from August 2008 to April 2009) \cite{Leskovec09-url}.\footnote{Unfortunately, the original article~\citep{Leskovec09} does not provide additional details on the source selection methodology.}
Quotations were then automatically extracted from this corpus: each quotation is a more or less faithful excerpt of an utterance (oral or written) by the quoted person. For instance,
\begin{quote}
The Bank of England said, ``these operations are designed to address funding pressures over quarter-end.''
\end{quote}
Quotations were then gathered in a graph and connected according to their similarity: either because they differ by very few words (in that case, no more than one word) or because they share a certain sequence of words (in that case, at least ten consecutive words). We find for example the following variation of the above quote: \begin{quote}``these operations are \textbf{intended} to address funding pressures over quarter-end.''\end{quote}
A community detection algorithm was applied to that quotation graph to detect aggregates of tightly connected, i.e. sufficiently similar, groups of quotations (see \citet{Leskovec09} for more detail).
This analysis yielded the final data we had access to, with a total of about \num{70000} sets of quotations; each of these sets allegedly contains all variations of a same parent utterance, along with their respective publication URLs and timestamps.

Manual inspection of this dataset revealed that it contains a significant number of everyday language quotations (such as ``it was much better than I expected'', ``did that just happen'', as well as many simple expletive-based sentences).
Their presence is largely due to random variations around a casual expression, while we are interested in transformations of news-related quotes causally linked to an original, identifiable utterance.
We thus filter out all clusters lasting more than 80 days, and all quotes less than 5 words long \seb{it is asymmetrical...} (as well as quotes not written in English).
We eventually keep 19,621 clusters (out of 71,568; i.e. 27.4\%), containing a total of 60,246 unique quotes (out of 310,457; i.e. 19.4\%) making up $\sim$838k occurrences (out of 8.12m, i.e. 10.3\%).
The significantly larger loss in occurrences indicates that, on average, the clusters we lose feature more occurrences than those we keep, which is expected for everyday language utterances.\footnote{While we lose real event-related utterances such as ``the terrorists have used automatic weapons and in some places grenades have been lobbed the encounters are still going on and we are trying to overpower them'', we contend that the use of the unfiltered dataset would strongly jeopardize results related to linguistic evolution or information diffusion. We could manually check on a subsample of clusters that a large proportion of remaining quotes seem to be relevant, while filtered quotes are essentially irrelevant.}

\subsection{Word-level measures}


\subsubsection{Standard psycholinguistic indices}

We now introduce some of the most classical psycholinguistic measures on words.

\begin{itemize}
    \item \textbf{Word frequency}: the frequency at which words appear in our dataset, known to be relevant for both recognition and recall~\citep{gregg1976word},
    \item \textbf{Age of Acquisition}: the average age at which words are learned (obtained from~\citet{kuperman12}), known to have different effects than word frequency~\citep{morrison1995roles,dewhurst1998separate},
    \item The average \textbf{Number of Phonemes} and \textbf{Number of Syllables} for all pronunciations of a word (obtained from the Carnegie Mellon University Pronouncing Dictionary~\citep{Weide98})\footnote{The CMU Pronouncing Dictionary is included in the NTLK package~\citep{Bird09}, the natural language processing toolkit we used for the analysis.} as a proxy to word production cost,
    \item The average \textbf{Number of Synonyms} for all meanings of a word (obtained from WordNet~\citep{WordNet10}) as a proxy to word polysemy.
\end{itemize}

We also considered grammatical types within quotations by detection of \emph{Part-of-Speech} (POS) categories, using the Penn TreeBank Project typology~\citep{Santorini90} and thereby distinguishing verbs, nouns, adjectives and adverbs.
The results were however extremely similar across the various categories, exhibiting no specific effect of words belonging to different POS categories.
\rk{See \#8 for this fact-check}

\subsubsection{Network-based measures}

Aside from classical psycholinguistic measures, we also considered more recently studied variables based on semantic network properties.
We relied on the ``free association'' norms collected by~\citet{Nelson04} which naturally embed information on the idea association process underlying transformation of quotations.

Free association (FA) norms record the words that come to mind when someone is presented with a given cue (that is the ``free association'' task).
As \citeauthor{Nelson04} explain,
\begin{quote}
free association response probabilities index the likelihood that one word can cue another word to come to mind with minimal contextual constraints in effect.~\citep{Nelson04}
\end{quote}
%Following \citet{Griffiths07}, we first consider the directed weighted network formed by the association norms, that is the network where words are nodes and edges are directed from cue to associated word, with a weight equal to the probability of that target word being produced when this particular cue was presented.
% \rk{we're in fact using the unweighed version of the network. Why?}
\new{Following \citet{Griffiths07}, we first build a directed unweighted network based on association norms, where words are nodes and edges are directed from cue to target word whenever a target word is being produced when this particular cue word was presented.}
This network is of particular interest since it measures the \emph{in-vitro forced-choice} version of a substitution whereas the data we analyse is the \emph{in-vivo spontaneous} version of what we otherwise hypothesize to be the same process.

\bigskip
We introduce three standard network-based measures to be used on the FA network% \rk{adapt once the weighing question (\#8) is settled}
:

\begin{itemize}
    \item \textbf{Centrality} $k$, initially measured by the number of incoming edges to a given node, i.e. the number of cues for which a given word is triggered as an association, which strongly relates to word polysemy.
    However in the present case there is a quasi-perfect correlation between node incoming degree and node \emph{pagerank}~\citep{Page99}, which will lead us to favour the latter later on. Word pagerank on the FA network had already been used by~\citet{Griffiths07}; it may be interpreted as a generalized and recursive measure of word polysemy: central nodes in the pagerank sense are words often selected as targets when presented with cues themselves often selected as targets, and so on recursively.
    \item \textbf{Clustering coefficient} $c$, which measures the extent to which a node belongs to a local aggregate of tightly connected nodes, and defined as the ratio between the number of actual vs. possible edges between a node's neighbours \cite{watt-coll}.
    We compute the clustering coefficient on the undirected version of the FA network; we thus measure if a word belongs more or less to a local aggregate of equivalent words (from a ``free association'' point of view).
    \item \textbf{Betweenness coefficient} $b$, another measure of node centrality describing the extent to which a node tends to connect otherwise remote areas of the network~\citep{free:set}.
    More technically, it corresponds to the normalized number of shortest paths connecting dyads which pass through that node; the higher the coefficient, the more important that node is in ensuring the connectedness of the rest of the network.
    This quantity tells us if some words behave like unavoidable waypoints on the path associating one word to another.
\end{itemize}

\subsubsection{Variable correlations}

An important question arises concerning the possible correlations between all the variables we use.

\begin{figure}[!th]
    \centering
    \includegraphics[width=\linewidth]{images/computed-figures/correlations-filter1.png}
    \caption{Spearman correlations in the initial set of features}
    \label{fig:feature-corrs-initial}
\end{figure}

\rk{Correlation talk needs to be redone for new set of features}

Age of acquisition is a key variable which appears as a usual suspect in psycholinguistic studies and is also usually correlated to many of the other variables.
This relates to an ongoing debate suggesting that age of acquisition encodes a variety of phenomena, difficult to disentangle from more specific phenomena which could be captured by more independent variables~\CN{}.
Here however, as can be seen in Figure~\ref{fig:feature-corrs-initial}, age of acquisition has a relatively low correlation to the other variables (absolute value not above $0.42$ if we exclude the centrality measures), leading us to keep the variable in the rest of the analysis.

Number of phonemes and number of syllables naturally exhibit a strong linear correlation ($0.83$).
The analysis showed a better prediction effect of number of phonemes over number of syllables, which is consistent with~\citet{nick-diss}, and we therefore chose to focus the presented results on the former only.

Frequency and number of meanings both have relatively low levels of correlation to the other variables; we therefore also keep them in the rest of the analysis.

\bigskip
Network properties, on the other hand, are strongly dependent on one another.
As mentioned earlier, word degree and word pagerank have a very strong correlation ($0.89$) and, degree being generally more correlated to other variables, we chose to remove this variable from the results presented.
Finally betweenness centrality also exhibits strong correlation levels to the other network properties ($0.62$, $0.64$, and $0.72$ in absolute value), leading us to drop this final feature due to its redundancy.

The final set of variables we consider, as well as their cross-correlations, can be seen in Figure~\ref{fig:feature-corrs-filtered}.

\begin{figure}[!th]
    \centering
    \includegraphics[width=0.6975\linewidth]{images/computed-figures/correlations-filter2.png}
    \caption{Spearman correlations in the filtered set of features}
    \label{fig:feature-corrs-filtered}
\end{figure}


\subsection{Substitution model}


%\subsubsection{Temporal binning}
\label{sec:temporal-binning}

We finally need a substitution detection model, for the utterance data we use presents a challenge: quote-to-quote transformations, and much less substitutions, are not explicitly encoded in the dataset. More precisely, each set of quotations bears no explicit information about either the authoritative original quotation, or the source quotation(s) each author relied on when creating a new post and reproducing (and possibly altering) that source.
We thus face an inference problem where, given all quotations and their occurrence timestamps, we should estimate which was the originating quotation for each instance of each quotation.

We therefore model the underlying quotation selection process by making a few additional assumptions.% which let us define quote-to-quote substitutions from the available data.
The main issue is deciding whether a later occurrence is a strict copy of an earlier occurrence, or a substitution of an even earlier occurrence, or perhaps even a substitution or copy from quotes appearing outside the dataset, \hbox{i.e.} from a source external to the data collection perimeter.

Let us give an example: say the quotation ``These accusations are false and \textbf{absurd}'' ($q$) appears in a blog on January 19, and the slightly different quotation ``These accusations are false and \textbf{incoherent}'' ($q'$) appears in other blogs on the 21st, 22nd and 23rd of January.
If $q$ was sufficiently prominent when $q'$ first appeared, we can safely assume that the first author of $q'$ on the 21st based himself on $q$ as is shown in Figure~\ref{fig:substitution-temporal-binning-a}.
But what about the second and third occurrences of $q'$, on the 22nd and 23rd?
Should we consider them to be substitutions based on $q$ %(i.e. re-creations of $q'$ by a new instance of the substitution process that brought from $q$ to $q'$ in the first place) 
or accurate reproductions of the previous occurrences of $q'$? (Options shown in Figure~\ref{fig:substitution-temporal-binning-a}.)

\begin{figure}[h]
    \centering
    \subfloat[Possible paths from occurrence to occurrence]{
	    \def\svgwidth{\linewidth}
	    \small
	    \input{images/substitution-temporal-binning-a.pdf_tex}
	    \label{fig:substitution-temporal-binning-a}
	}
	\hfill \\
    \subfloat[Binned quotation family]{
	    \def\svgwidth{\linewidth}
	    \small
	    \input{images/substitution-temporal-binning-b.pdf_tex}
	    \label{fig:substitution-temporal-binning-b}
	}
	\hfill \\
	\subfloat[XXXX]{
	    \def\svgwidth{\linewidth}
	    \small
		\input{images/substitution-q_max.pdf_tex}
	    \label{fig:substitution-q_max}
	}
	\caption{Temporal binning of quotation families}
    \label{fig:substitution-temporal-binning}
\end{figure}

To settle this question we bin the quote occurrences into fixed \emph{bins} spanning $\Delta t$ days (2 days in the implementation), each one representing a unit of time evolution.
Then when a quotation $q$ appears in bin $n$, it is counted as a substitution from each quote $q^*$ in the preceding bin ($n - 1$) from which it differs by only one word.
If no quote in the preceding bin can qualify as a source in a substitution (i.e. $q$ differs from all the quotes in the preceding bin by more than one word), the occurrence of $q$ is not considered to be an instance of substitution.
Such a model defines how many times quote occurrences can be counted as substitutions: in Figure~\ref{fig:substitution-temporal-binning-b}, occurrences of $q'$ on the 21st and 22nd are counted as substitutions, whereas the occurrence on the 23rd is not.

The assumptions embedded in this model are only a subset of a wider set of possibilities, each leading to alternative substitution inferences.\footnote{In particular, time can be sliced into fixed bins as is done here, or kept fine-grained by using sliding bins.}
These various flavours of an ideal substitution detection model essentially change whether occurrences are considered as substitutions from another quote, repetitions of the original quote, or introduction of information external to the dataset.
We identified and implemented eleven other such models, and they all yielded essentially the same results.

We now need to reduce possible false positives.
Indeed, so far we have been forced to detect substitutions with a very permissive model to make sure chains of substitutions could be extracted (at the expense of possible false positives, the only effect of this being additional noise in the results, making our conclusions more conservative), here we can afford to detect substitutions more precisely.
We thus add the constraint that substitutions can only stem from the most frequent quote in the preceding bin.
We assume that authors will have encountered the most frequent quote in a given bin (\hbox{vs.} all the other quotes in that bin). Thus, restricting substitutions to the most frequent quote ensures that we only detect substitutions that really occurred, greatly reducing the number of false positives.

Let us illustrate this ``majority'' rule by going back to the example described in Section~\ref{sec:temporal-binning} and extending it, in Figure~\ref{fig:substitution-q_max}.
In bin~3, $q'$ now holds the majority and is considered the unique basis for the last occurrence of $q$ (in bin~4).
This is despite the fact that $q$ also appears in bin~3 alongside $q'$, and despite it having appeared earlier at the very beginning of the quotation family (indeed in the situation shown in Figure~\ref{fig:substitution-q_max}, this seems to be the most likely scenario).
Conversely, if $q$ had been the most frequent quote in bin~3, the last occurrence of $q$ in bin~4 would have been considered a faithful copy of the occurrence in bin~3.


With the substitution detection model thus refined, we build two main observables for each word feature.
First, we measure the susceptibility for words to be the source of a substitution, knowing that there has been a variation, in order to show which semantic features are the most likely to attract a substitution under this condition.
Second, we measure the variation of word feature over a substitution, looking at the variation of a given feature between start and arrival words.

Note that since we only consider substitutions and not faithful copies, we measure the features of an alteration \emph{knowing that there has been an alteration}, and we do not take invariant quotations into account.
Indeed, in the first case we know there has been a human reformulation, whereas in the second case it is impossible to know whether there has been perfect human reformulation or simply digital copy-pasting of a source (``{\sc Ctrl-C}/{\sc Ctrl-V}'').

\section{Results}\label{sec:results}

\subsection{Susceptibility}

For a given feature $\phi$, the protocol lets us compute substitution \emph{susceptibilities} for each feature value $f$.
We say that a word is \emph{substitutable} if it appears in a quote which undergoes a substitution, whether that substitution operates on the considered word or on another.
Word substitution susceptibility is computed as the ratio of the number $s_w$ of times a word is substituted to the number $p_w$ of times that word appears in a substitutable position, i.e. $\sfrac{s_w}{p_w}$.

Now averaging over all words such that $\phi(w) = f$ (only taking into account words that are substituted at least once), we obtain the mean susceptibility for the feature value $f$:
\footnote{To avoid any auto-correlation effect due to the number of substitutions in a cluster (possibly leading to an overly optimistic estimation of confidence intervals), we first average substitutions over each cluster, by considering the average of arrival word features for a given start word.
Indeed, substitutions occurring in the same cluster are likely not statistically independent.}
$$\sigma_{\phi}(f) = \left< \frac{s_w}{p_w} \right>_{\left\lbrace w | \phi(w) = f \right\rbrace}$$

This measure focuses on the selection of start words involved in substitutions, measuring the effect of features at the moment preceding the substitution when it is not yet known which word in the quotation -- if any -- will be substituted.

\subsection{Alteration}

Next, we measure how a word $\wstart$'s feature varies as $\wstart$ is substituted by $\warrival$, i.e. $\phi(\warrival) - \phi(\wstart)$.
Averaging this value over all start words such that $\phi(w) = f$ yields the mean variation for that feature value~$f$:
$$\Delta_{\phi}(f) = \left< \phi(\warrival) - \phi(\wstart) \right>_{\left\lbrace (\wstart,\warrival) | \phi(\wstart) = f \right\rbrace}$$

We introduce a null hypothesis $\mathcal{H}_0$ to compare the actual variation of a word's feature to its expected variation, assuming the arrival word $\warrival_0$ had been chosen randomly from the pool of free association words.
The new quantity under $\mathcal{H}_0$ is:
\footnote{Note that $\phi(\warrival_0)$ is in fact a constant in this averaging, since by definition $\warrival_0$ does not depend on $\wstart$.}
$$\Delta_{\phi}^0 (f) = \left< \phi({\warrival_0}) - \phi(\wstart) \right>_{\left\lbrace (\wstart,\warrival_0) | \phi(\wstart) = f \right\rbrace}$$

We also considered an alternative null hypothesis, denoted $\mathcal{H}_{00}$, where the arrival word is chosen randomly \emph{among immediate synonyms of the start word}, i.e. an arrival word chosen among semantically plausible though still random words.\footnote{In this case $\warrival_{00}$ does depend on $\wstart$.}
The results were not qualitatively changed with this second null hypothesis, so for the sake of clarity we chose to present the results using the simpler~$\mathcal{H}_0$.

Using this method we obtain the mean variation of feature for each start feature value, and can compare the variations to a situation where arrival words are chosen randomly.
This gives us a fine-grained view of how word features evolve upon substitution.


\rk{Comment results}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/feature_susceptibilities.png}
    \caption{\textbf{Substitution susceptibility:} average susceptibility to substitution vs. average feature value of a candidate word for substitution, with 95\% asymptotic confidence intervals.
    Each feature exhibits a specific and significant pattern favouring either high- or low-valued words for substitution.}
    \label{fig:feature-susceptibilities}
\end{figure*}

\begin{figure*}[!th]
    \centering
    \includegraphics[width=\textwidth]{images/computed-figures/feature_variations-binned.png}
    \caption{\textbf{Feature variation upon substitution:} average feature of the appearing word minus $\mathcal{H}_0$ vs. average feature of the disappearing word in a substitution, with 95\% asymptotic confidence intervals.
    The overall position of the curve with respect to $y = 0$ indicates the direction of the cognitive bias.
    The fact that all the curves have slopes smaller than 1 means that the substitution operation is contractile on average: each feature will converge towards its own specific asymptotic range, which is consistent with the evolution observed in Figure~\ref{fig:timebags-evolution}.}
    \label{fig:feature-variations}
\end{figure*}